#!/usr/bin/env python3
"""
æ•°æ®åº“ä¼˜åŒ–ç®¡ç†å·¥å…· v2.6.4
é›†æˆæ‰€æœ‰æ•°æ®åº“ä¼˜åŒ–åŠŸèƒ½çš„ç»Ÿä¸€ç®¡ç†è„šæœ¬
"""

import argparse
import os
import sys
import json
import time
import logging
from pathlib import Path
from datetime import datetime, date
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('database_manager.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class Colors:
    """é¢œè‰²è¾“å‡ºç±»"""
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[0;33m'
    BLUE = '\033[0;34m'
    CYAN = '\033[0;36m'
    WHITE = '\033[0;37m'
    BOLD = '\033[1m'
    NC = '\033[0m'  # No Color


class DatabaseOptimizationManager:
    """æ•°æ®åº“ä¼˜åŒ–ç®¡ç†å™¨"""
    
    def __init__(self, database_url: str):
        self.database_url = database_url
        self.script_dir = Path(__file__).parent
        self.project_root = self.script_dir.parent.parent
        
        # è§£ææ•°æ®åº“è¿æ¥ä¿¡æ¯
        self._parse_database_url()
        
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
        self._init_database()
    
    def _parse_database_url(self):
        """è§£ææ•°æ®åº“URL"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(self.database_url)
            
            self.db_type = parsed.scheme.split('+')[0]  # mysql
            self.db_host = parsed.hostname
            self.db_port = parsed.port or 3306
            self.db_user = parsed.username
            self.db_password = parsed.password
            self.db_name = parsed.path.lstrip('/')
            
            logger.info(f"æ•°æ®åº“é…ç½®: {self.db_type}://{self.db_host}:{self.db_port}/{self.db_name}")
            
        except Exception as e:
            logger.error(f"è§£ææ•°æ®åº“URLå¤±è´¥: {e}")
            raise
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥"""
        try:
            from sqlalchemy import create_engine
            from sqlalchemy.orm import sessionmaker
            
            self.engine = create_engine(self.database_url, echo=False)
            self.SessionLocal = sessionmaker(bind=self.engine)
            
            # æµ‹è¯•è¿æ¥
            with self.engine.connect() as conn:
                conn.execute("SELECT 1")
            
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    def print_status(self, message: str, status: str = "info"):
        """æ‰“å°å¸¦é¢œè‰²çš„çŠ¶æ€ä¿¡æ¯"""
        colors = {
            "info": Colors.BLUE,
            "success": Colors.GREEN,
            "warning": Colors.YELLOW,
            "error": Colors.RED,
            "cyan": Colors.CYAN
        }
        
        color = colors.get(status, Colors.WHITE)
        print(f"{color}{message}{Colors.NC}")
    
    def check_optimization_status(self) -> Dict[str, Any]:
        """æ£€æŸ¥ä¼˜åŒ–çŠ¶æ€"""
        self.print_status("ğŸ” æ£€æŸ¥æ•°æ®åº“ä¼˜åŒ–çŠ¶æ€...", "info")
        
        status = {
            "environment": {},
            "tables": {},
            "views": {},
            "data_counts": {},
            "performance": {}
        }
        
        try:
            with self.SessionLocal() as db:
                # æ£€æŸ¥ç¯å¢ƒå˜é‡
                env_vars = [
                    'USE_OPTIMIZED_TABLES',
                    'ENABLE_PERFORMANCE_LOG',
                    'ENABLE_QUERY_CACHE',
                    'API_PERFORMANCE_MONITORING'
                ]
                
                for var in env_vars:
                    status["environment"][var] = os.getenv(var, 'false')
                
                # æ£€æŸ¥ä¼˜åŒ–è¡¨
                optimized_tables = [
                    'daily_trading_unified',
                    'concept_daily_metrics',
                    'stock_concept_daily_snapshot',
                    'today_trading_cache'
                ]
                
                for table in optimized_tables:
                    try:
                        result = db.execute(f"SHOW TABLES LIKE '{table}'").fetchone()
                        exists = result is not None
                        status["tables"][table] = exists
                        
                        if exists:
                            count = db.execute(f"SELECT COUNT(*) FROM {table}").scalar()
                            status["data_counts"][table] = count
                        
                    except Exception as e:
                        status["tables"][table] = False
                        logger.error(f"æ£€æŸ¥è¡¨ {table} å¤±è´¥: {e}")
                
                # æ£€æŸ¥ä¼˜åŒ–è§†å›¾
                optimized_views = [
                    'v_stock_daily_summary',
                    'v_concept_daily_ranking',
                    'v_stock_concept_performance'
                ]
                
                for view in optimized_views:
                    try:
                        db.execute(f"SELECT 1 FROM {view} LIMIT 1")
                        status["views"][view] = True
                    except Exception:
                        status["views"][view] = False
                
                # æ£€æŸ¥åŸå§‹è¡¨æ•°æ®é‡
                original_tables = [
                    'daily_trading',
                    'concept_daily_summary',
                    'stock_concept_ranking'
                ]
                
                for table in original_tables:
                    try:
                        count = db.execute(f"SELECT COUNT(*) FROM {table}").scalar()
                        status["data_counts"][f"{table}_original"] = count
                    except Exception:
                        status["data_counts"][f"{table}_original"] = 0
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥ä¼˜åŒ–çŠ¶æ€å¤±è´¥: {e}")
            status["error"] = str(e)
        
        return status
    
    def create_optimized_tables(self) -> bool:
        """åˆ›å»ºä¼˜åŒ–è¡¨ç»“æ„"""
        self.print_status("ğŸ—ï¸ åˆ›å»ºä¼˜åŒ–è¡¨ç»“æ„...", "info")
        
        try:
            # æ‰§è¡Œå»ºè¡¨è„šæœ¬
            tables_script = self.script_dir / "create_optimized_tables.sql"
            views_script = self.script_dir / "create_views_and_indexes.sql"
            
            if not tables_script.exists():
                self.print_status(f"å»ºè¡¨è„šæœ¬ä¸å­˜åœ¨: {tables_script}", "error")
                return False
            
            # ä½¿ç”¨mysqlå‘½ä»¤æ‰§è¡Œè„šæœ¬
            import subprocess
            
            cmd = [
                "mysql",
                f"-h{self.db_host}",
                f"-P{self.db_port}",
                f"-u{self.db_user}",
                f"-p{self.db_password}",
                self.db_name
            ]
            
            # æ‰§è¡Œå»ºè¡¨è„šæœ¬
            with open(tables_script, 'r') as f:
                result = subprocess.run(cmd, input=f.read(), text=True, 
                                      capture_output=True)
            
            if result.returncode != 0:
                self.print_status(f"å»ºè¡¨è„šæœ¬æ‰§è¡Œå¤±è´¥: {result.stderr}", "error")
                return False
            
            self.print_status("âœ“ ä¼˜åŒ–è¡¨åˆ›å»ºå®Œæˆ", "success")
            
            # åˆ›å»ºè§†å›¾å’Œç´¢å¼•
            if views_script.exists():
                with open(views_script, 'r') as f:
                    result = subprocess.run(cmd, input=f.read(), text=True,
                                          capture_output=True)
                
                if result.returncode != 0:
                    self.print_status(f"è§†å›¾åˆ›å»ºå¤±è´¥: {result.stderr}", "warning")
                else:
                    self.print_status("âœ“ ä¼˜åŒ–è§†å›¾åˆ›å»ºå®Œæˆ", "success")
            
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºä¼˜åŒ–è¡¨å¤±è´¥: {e}")
            self.print_status(f"åˆ›å»ºä¼˜åŒ–è¡¨å¤±è´¥: {e}", "error")
            return False
    
    def migrate_data(self, start_date: Optional[str] = None, 
                    end_date: Optional[str] = None) -> bool:
        """è¿ç§»æ•°æ®åˆ°ä¼˜åŒ–è¡¨"""
        self.print_status("ğŸ“¦ æ‰§è¡Œæ•°æ®è¿ç§»...", "info")
        
        try:
            import subprocess
            
            migration_script = self.script_dir / "smooth_migration_service.py"
            
            if not migration_script.exists():
                self.print_status(f"è¿ç§»è„šæœ¬ä¸å­˜åœ¨: {migration_script}", "error")
                return False
            
            cmd = [
                "python3", str(migration_script),
                "--database-url", self.database_url
            ]
            
            if start_date:
                cmd.extend(["--start-date", start_date])
            if end_date:
                cmd.extend(["--end-date", end_date])
            
            # æ‰§è¡Œè¿ç§»è„šæœ¬
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                self.print_status("âœ“ æ•°æ®è¿ç§»å®Œæˆ", "success")
                return True
            else:
                self.print_status(f"æ•°æ®è¿ç§»å¤±è´¥: {result.stderr}", "error")
                return False
                
        except Exception as e:
            logger.error(f"æ•°æ®è¿ç§»å¤±è´¥: {e}")
            self.print_status(f"æ•°æ®è¿ç§»å¤±è´¥: {e}", "error")
            return False
    
    def enable_optimization(self, mode: str = "optimized") -> bool:
        """å¯ç”¨ä¼˜åŒ–åŠŸèƒ½"""
        self.print_status(f"âš™ï¸ å¯ç”¨ä¼˜åŒ–åŠŸèƒ½ (æ¨¡å¼: {mode})...", "info")
        
        try:
            import subprocess
            
            enable_script = self.script_dir / "enable_optimization.py"
            
            if not enable_script.exists():
                self.print_status(f"å¯ç”¨è„šæœ¬ä¸å­˜åœ¨: {enable_script}", "error")
                return False
            
            cmd = [
                "python3", str(enable_script),
                "enable", "--mode", mode
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                self.print_status("âœ“ ä¼˜åŒ–åŠŸèƒ½å·²å¯ç”¨", "success")
                return True
            else:
                self.print_status(f"å¯ç”¨ä¼˜åŒ–åŠŸèƒ½å¤±è´¥: {result.stderr}", "error")
                return False
                
        except Exception as e:
            logger.error(f"å¯ç”¨ä¼˜åŒ–åŠŸèƒ½å¤±è´¥: {e}")
            self.print_status(f"å¯ç”¨ä¼˜åŒ–åŠŸèƒ½å¤±è´¥: {e}", "error")
            return False
    
    def performance_test(self, trading_date: Optional[str] = None) -> Dict[str, Any]:
        """æ€§èƒ½æµ‹è¯•"""
        if not trading_date:
            trading_date = "2025-09-02"  # é»˜è®¤æµ‹è¯•æ—¥æœŸ
        
        self.print_status(f"ğŸš€ æ‰§è¡Œæ€§èƒ½æµ‹è¯• (æ—¥æœŸ: {trading_date})...", "info")
        
        results = {
            "testing_date": trading_date,
            "original_query": {},
            "optimized_query": {},
            "improvement": {}
        }
        
        try:
            with self.SessionLocal() as db:
                parsed_date = datetime.strptime(trading_date, '%Y-%m-%d').date()
                
                # æµ‹è¯•åŸå§‹æŸ¥è¯¢
                self.print_status("æµ‹è¯•åŸå§‹æŸ¥è¯¢æ€§èƒ½...", "cyan")
                start_time = time.time()
                
                try:
                    original_count = db.execute(
                        "SELECT COUNT(*) FROM daily_trading WHERE trading_date = %s",
                        (parsed_date,)
                    ).scalar()
                    original_time = (time.time() - start_time) * 1000
                    
                    results["original_query"] = {
                        "record_count": original_count,
                        "execution_time_ms": round(original_time, 2),
                        "status": "success"
                    }
                    
                except Exception as e:
                    results["original_query"] = {
                        "record_count": 0,
                        "execution_time_ms": -1,
                        "status": f"failed: {e}"
                    }
                
                # æµ‹è¯•ä¼˜åŒ–æŸ¥è¯¢
                self.print_status("æµ‹è¯•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½...", "cyan")
                start_time = time.time()
                
                try:
                    # æ£€æŸ¥ä¼˜åŒ–è¡¨æ˜¯å¦å­˜åœ¨
                    table_check = db.execute(
                        "SHOW TABLES LIKE 'daily_trading_unified'"
                    ).fetchone()
                    
                    if table_check:
                        optimized_count = db.execute(
                            "SELECT COUNT(*) FROM daily_trading_unified WHERE trading_date = %s",
                            (parsed_date,)
                        ).scalar()
                        optimized_time = (time.time() - start_time) * 1000
                        
                        results["optimized_query"] = {
                            "record_count": optimized_count,
                            "execution_time_ms": round(optimized_time, 2),
                            "status": "success"
                        }
                        
                        # è®¡ç®—æ€§èƒ½æå‡
                        if original_time > 0 and optimized_time > 0:
                            improvement_factor = original_time / optimized_time
                            results["improvement"] = {
                                "factor": round(improvement_factor, 2),
                                "description": f"{improvement_factor:.1f}å€æå‡",
                                "time_saved_ms": round(original_time - optimized_time, 2)
                            }
                    else:
                        results["optimized_query"] = {
                            "record_count": 0,
                            "execution_time_ms": -1,
                            "status": "table not exists"
                        }
                        
                except Exception as e:
                    results["optimized_query"] = {
                        "record_count": 0,
                        "execution_time_ms": -1,
                        "status": f"failed: {e}"
                    }
        
        except Exception as e:
            logger.error(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            results["error"] = str(e)
        
        return results
    
    def backup_database(self) -> str:
        """å¤‡ä»½æ•°æ®åº“"""
        self.print_status("ğŸ’¾ å¤‡ä»½æ•°æ®åº“...", "info")
        
        try:
            import subprocess
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_file = self.project_root / f"database_backup_{timestamp}.sql"
            
            cmd = [
                "mysqldump",
                f"-h{self.db_host}",
                f"-P{self.db_port}",
                f"-u{self.db_user}",
                f"-p{self.db_password}",
                "--single-transaction",
                "--routines",
                "--triggers",
                self.db_name
            ]
            
            with open(backup_file, 'w') as f:
                result = subprocess.run(cmd, stdout=f, stderr=subprocess.PIPE, text=True)
            
            if result.returncode == 0:
                self.print_status(f"âœ“ æ•°æ®åº“å¤‡ä»½å®Œæˆ: {backup_file}", "success")
                return str(backup_file)
            else:
                self.print_status(f"æ•°æ®åº“å¤‡ä»½å¤±è´¥: {result.stderr}", "error")
                return ""
                
        except Exception as e:
            logger.error(f"æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")
            self.print_status(f"æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}", "error")
            return ""
    
    def full_deployment(self) -> bool:
        """å®Œæ•´éƒ¨ç½²æµç¨‹"""
        self.print_status("ğŸš€ å¼€å§‹å®Œæ•´ä¼˜åŒ–éƒ¨ç½²...", "info")
        
        steps = [
            ("å¤‡ä»½æ•°æ®åº“", self.backup_database),
            ("åˆ›å»ºä¼˜åŒ–è¡¨", self.create_optimized_tables),
            ("è¿ç§»æ•°æ®", self.migrate_data),
            ("å¯ç”¨ä¼˜åŒ–", lambda: self.enable_optimization("optimized"))
        ]
        
        for step_name, step_func in steps:
            self.print_status(f"æ‰§è¡Œ: {step_name}", "cyan")
            
            try:
                if step_name == "å¤‡ä»½æ•°æ®åº“":
                    result = step_func()
                    success = bool(result)
                else:
                    success = step_func()
                
                if success:
                    self.print_status(f"âœ“ {step_name} å®Œæˆ", "success")
                else:
                    self.print_status(f"âœ— {step_name} å¤±è´¥", "error")
                    return False
                    
            except Exception as e:
                self.print_status(f"âœ— {step_name} å¼‚å¸¸: {e}", "error")
                return False
        
        self.print_status("ğŸ‰ å®Œæ•´ä¼˜åŒ–éƒ¨ç½²æˆåŠŸï¼", "success")
        return True
    
    def print_report(self):
        """æ‰“å°çŠ¶æ€æŠ¥å‘Š"""
        print("\n" + "="*60)
        print(f"{Colors.BOLD}{Colors.GREEN}æ•°æ®åº“ä¼˜åŒ–çŠ¶æ€æŠ¥å‘Š{Colors.NC}")
        print("="*60)
        
        status = self.check_optimization_status()
        
        # ç¯å¢ƒé…ç½®
        print(f"\n{Colors.CYAN}ğŸ“Š ç¯å¢ƒé…ç½®:{Colors.NC}")
        for key, value in status.get("environment", {}).items():
            color = Colors.GREEN if value.lower() == 'true' else Colors.YELLOW
            print(f"  â€¢ {key}: {color}{value}{Colors.NC}")
        
        # è¡¨çŠ¶æ€
        print(f"\n{Colors.CYAN}ğŸ—ƒï¸ ä¼˜åŒ–è¡¨çŠ¶æ€:{Colors.NC}")
        for table, exists in status.get("tables", {}).items():
            color = Colors.GREEN if exists else Colors.RED
            count = status.get("data_counts", {}).get(table, 0)
            status_text = f"å­˜åœ¨ ({count} æ¡è®°å½•)" if exists else "ä¸å­˜åœ¨"
            print(f"  â€¢ {table}: {color}{status_text}{Colors.NC}")
        
        # è§†å›¾çŠ¶æ€
        print(f"\n{Colors.CYAN}ğŸ‘ï¸ ä¼˜åŒ–è§†å›¾çŠ¶æ€:{Colors.NC}")
        for view, exists in status.get("views", {}).items():
            color = Colors.GREEN if exists else Colors.RED
            status_text = "å¯ç”¨" if exists else "ä¸å¯ç”¨"
            print(f"  â€¢ {view}: {color}{status_text}{Colors.NC}")
        
        # æ•°æ®å¯¹æ¯”
        print(f"\n{Colors.CYAN}ğŸ“ˆ æ•°æ®é‡å¯¹æ¯”:{Colors.NC}")
        original_daily = status.get("data_counts", {}).get("daily_trading_original", 0)
        optimized_daily = status.get("data_counts", {}).get("daily_trading_unified", 0)
        print(f"  â€¢ æ¯æ—¥äº¤æ˜“æ•°æ®: {original_daily} â†’ {optimized_daily}")
        
        # æ•´ä½“çŠ¶æ€
        tables_ready = sum(1 for x in status.get("tables", {}).values() if x)
        total_tables = len(status.get("tables", {}))
        overall_ready = tables_ready == total_tables and tables_ready > 0
        
        print(f"\n{Colors.CYAN}ğŸ¯ æ•´ä½“çŠ¶æ€:{Colors.NC}")
        color = Colors.GREEN if overall_ready else Colors.YELLOW
        status_text = "å·²å°±ç»ª" if overall_ready else "æœªå®Œæˆ"
        print(f"  â€¢ ä¼˜åŒ–çŠ¶æ€: {color}{status_text}{Colors.NC}")
        print(f"  â€¢ è¡¨å®Œæˆåº¦: {tables_ready}/{total_tables}")
        
        print("\n" + "="*60)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ•°æ®åº“ä¼˜åŒ–ç®¡ç†å·¥å…· v2.6.4")
    parser.add_argument("--db-url", required=True, help="æ•°æ®åº“è¿æ¥URL")
    
    subparsers = parser.add_subparsers(dest="action", help="æ“ä½œå‘½ä»¤")
    
    # çŠ¶æ€æ£€æŸ¥
    subparsers.add_parser("status", help="æ£€æŸ¥ä¼˜åŒ–çŠ¶æ€")
    
    # åˆ›å»ºè¡¨ç»“æ„
    subparsers.add_parser("create-tables", help="åˆ›å»ºä¼˜åŒ–è¡¨ç»“æ„")
    
    # æ•°æ®è¿ç§»
    migrate_parser = subparsers.add_parser("migrate", help="è¿ç§»æ•°æ®")
    migrate_parser.add_argument("--start-date", help="å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)")
    migrate_parser.add_argument("--end-date", help="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)")
    
    # å¯ç”¨ä¼˜åŒ–
    enable_parser = subparsers.add_parser("enable", help="å¯ç”¨ä¼˜åŒ–åŠŸèƒ½")
    enable_parser.add_argument("--mode", default="optimized", 
                             choices=["testing", "optimized", "production"],
                             help="å¯ç”¨æ¨¡å¼")
    
    # æ€§èƒ½æµ‹è¯•
    test_parser = subparsers.add_parser("test", help="æ€§èƒ½æµ‹è¯•")
    test_parser.add_argument("--date", help="æµ‹è¯•æ—¥æœŸ (YYYY-MM-DD)")
    
    # æ•°æ®åº“å¤‡ä»½
    subparsers.add_parser("backup", help="å¤‡ä»½æ•°æ®åº“")
    
    # å®Œæ•´éƒ¨ç½²
    subparsers.add_parser("deploy", help="å®Œæ•´ä¼˜åŒ–éƒ¨ç½²")
    
    # çŠ¶æ€æŠ¥å‘Š
    subparsers.add_parser("report", help="ç”ŸæˆçŠ¶æ€æŠ¥å‘Š")
    
    args = parser.parse_args()
    
    if not args.action:
        parser.print_help()
        return
    
    # åˆå§‹åŒ–ç®¡ç†å™¨
    try:
        manager = DatabaseOptimizationManager(args.db_url)
    except Exception as e:
        print(f"{Colors.RED}åˆå§‹åŒ–å¤±è´¥: {e}{Colors.NC}")
        return
    
    # æ‰§è¡Œç›¸åº”æ“ä½œ
    try:
        if args.action == "status":
            status = manager.check_optimization_status()
            print(json.dumps(status, indent=2, ensure_ascii=False))
        
        elif args.action == "create-tables":
            success = manager.create_optimized_tables()
            sys.exit(0 if success else 1)
        
        elif args.action == "migrate":
            success = manager.migrate_data(args.start_date, args.end_date)
            sys.exit(0 if success else 1)
        
        elif args.action == "enable":
            success = manager.enable_optimization(args.mode)
            sys.exit(0 if success else 1)
        
        elif args.action == "test":
            results = manager.performance_test(args.date)
            print(json.dumps(results, indent=2, ensure_ascii=False))
        
        elif args.action == "backup":
            backup_file = manager.backup_database()
            sys.exit(0 if backup_file else 1)
        
        elif args.action == "deploy":
            success = manager.full_deployment()
            sys.exit(0 if success else 1)
        
        elif args.action == "report":
            manager.print_report()
    
    except Exception as e:
        print(f"{Colors.RED}æ“ä½œæ‰§è¡Œå¤±è´¥: {e}{Colors.NC}")
        sys.exit(1)


if __name__ == "__main__":
    main()