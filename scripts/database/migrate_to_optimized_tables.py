#!/usr/bin/env python3
"""
æ•°æ®åº“ä¼˜åŒ–è¿ç§»è„šæœ¬ v2.6.4
ç›®æ ‡ï¼šå°†ç°æœ‰æ•°æ®è¿ç§»åˆ°ä¼˜åŒ–åçš„è¡¨ç»“æ„
æ‰§è¡Œï¼špython migrate_to_optimized_tables.py
"""

import sys
import os
import time
from datetime import datetime, date, timedelta
from typing import List, Dict, Any
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from sqlalchemy import create_engine, text, func
from sqlalchemy.orm import sessionmaker
from backend.app.core.database import engine, SessionLocal
from backend.app.models.daily_trading import DailyTrading, ConceptDailySummary, StockConceptRanking
from backend.app.models.stock import Stock
from backend.app.models.concept import Concept

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('migration.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DatabaseMigration:
    """æ•°æ®åº“è¿ç§»ç±»"""
    
    def __init__(self):
        self.db = SessionLocal()
        self.batch_size = 5000
        self.start_time = time.time()
        self.stats = {
            'daily_trading': 0,
            'concept_metrics': 0, 
            'stock_concept_snapshot': 0,
            'errors': 0
        }
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.db.close()
        if exc_type:
            logger.error(f"è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {exc_val}")
    
    def log_progress(self, message: str):
        """è®°å½•è¿›åº¦"""
        elapsed = time.time() - self.start_time
        logger.info(f"[{elapsed:.1f}s] {message}")
    
    def migrate_daily_trading_data(self):
        """è¿ç§»æ¯æ—¥äº¤æ˜“æ•°æ®åˆ°ç»Ÿä¸€è¡¨"""
        self.log_progress("å¼€å§‹è¿ç§»æ¯æ—¥äº¤æ˜“æ•°æ®...")
        
        try:
            # 1. è·å–ç°æœ‰æ•°æ®ç»Ÿè®¡
            total_count = self.db.query(DailyTrading).count()
            self.log_progress(f"å‘ç° {total_count} æ¡æ¯æ—¥äº¤æ˜“è®°å½•")
            
            # 2. æ‰¹é‡è¿ç§»æ•°æ®
            offset = 0
            migrated = 0
            
            while True:
                # åˆ†æ‰¹è·å–æ•°æ®
                batch_data = self.db.query(DailyTrading).offset(offset).limit(self.batch_size).all()
                if not batch_data:
                    break
                
                # å‡†å¤‡æ’å…¥æ•°æ®
                insert_data = []
                for record in batch_data:
                    # è·å–è‚¡ç¥¨åç§°
                    stock_name = self.get_stock_name(record.stock_code)
                    
                    # è®¡ç®—æ¦‚å¿µæ•°é‡
                    concept_count = self.get_concept_count(record.stock_code, record.trading_date)
                    
                    insert_data.append({
                        'stock_code': record.stock_code,
                        'stock_name': stock_name,
                        'trading_date': record.trading_date,
                        'trading_volume': record.trading_volume,
                        'heat_value': 0,  # é»˜è®¤å€¼ï¼Œåç»­å¯ä»å…¶ä»–è¡¨è¡¥å……
                        'concept_count': concept_count,
                        'rank_in_date': 0,  # ç¨åæ‰¹é‡è®¡ç®—
                        'volume_rank_pct': 0.0,
                        'created_at': record.created_at or datetime.now()
                    })
                
                # æ‰¹é‡æ’å…¥
                if insert_data:
                    insert_sql = """
                    INSERT IGNORE INTO daily_trading_unified 
                    (stock_code, stock_name, trading_date, trading_volume, heat_value, 
                     concept_count, rank_in_date, volume_rank_pct, created_at)
                    VALUES 
                    """ + ','.join([
                        f"('{d['stock_code']}', '{d['stock_name']}', '{d['trading_date']}', "
                        f"{d['trading_volume']}, {d['heat_value']}, {d['concept_count']}, "
                        f"{d['rank_in_date']}, {d['volume_rank_pct']}, '{d['created_at']}')"
                        for d in insert_data
                    ])
                    
                    self.db.execute(text(insert_sql))
                    self.db.commit()
                    
                    migrated += len(insert_data)
                    self.log_progress(f"å·²è¿ç§» {migrated}/{total_count} æ¡äº¤æ˜“è®°å½•")
                
                offset += self.batch_size
            
            self.stats['daily_trading'] = migrated
            
            # 3. æ‰¹é‡è®¡ç®—æ’å
            self.calculate_daily_rankings()
            
            self.log_progress(f"æ¯æ—¥äº¤æ˜“æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {migrated} æ¡è®°å½•")
            
        except Exception as e:
            logger.error(f"è¿ç§»æ¯æ—¥äº¤æ˜“æ•°æ®å¤±è´¥: {e}")
            self.stats['errors'] += 1
            raise
    
    def migrate_concept_metrics(self):
        """è¿ç§»æ¦‚å¿µæ±‡æ€»æ•°æ®"""
        self.log_progress("å¼€å§‹è¿ç§»æ¦‚å¿µæ±‡æ€»æ•°æ®...")
        
        try:
            # 1. è·å–ç°æœ‰æ•°æ®
            total_count = self.db.query(ConceptDailySummary).count()
            self.log_progress(f"å‘ç° {total_count} æ¡æ¦‚å¿µæ±‡æ€»è®°å½•")
            
            # 2. æ‰¹é‡è¿ç§»
            offset = 0
            migrated = 0
            
            while True:
                batch_data = self.db.query(ConceptDailySummary).offset(offset).limit(self.batch_size).all()
                if not batch_data:
                    break
                
                insert_data = []
                for record in batch_data:
                    # è®¡ç®—å‰ä¸€æ—¥äº¤æ˜“é‡ï¼ˆç”¨äºå˜åŒ–ç™¾åˆ†æ¯”ï¼‰
                    prev_volume = self.get_prev_day_volume(record.concept_name, record.trading_date)
                    
                    # è®¡ç®—å˜åŒ–ç™¾åˆ†æ¯”
                    volume_change_pct = 0.0
                    if prev_volume > 0:
                        volume_change_pct = ((record.total_volume - prev_volume) / prev_volume) * 100
                    
                    insert_data.append({
                        'concept_name': record.concept_name,
                        'trading_date': record.trading_date,
                        'total_volume': record.total_volume,
                        'stock_count': record.stock_count,
                        'avg_volume': record.average_volume,
                        'max_volume': record.max_volume,
                        'min_volume': 0,  # æ–°å­—æ®µï¼Œéœ€è¦é‡æ–°è®¡ç®—
                        'volume_rank': 0,  # ç¨åæ‰¹é‡è®¡ç®—
                        'stock_count_rank': 0,  # ç¨åæ‰¹é‡è®¡ç®—
                        'is_new_high': False,  # ç¨åè®¡ç®—
                        'new_high_days': 0,
                        'volume_change_pct': volume_change_pct,
                        'prev_day_volume': prev_volume,
                        'created_at': record.created_at or datetime.now()
                    })
                
                # æ‰¹é‡æ’å…¥
                if insert_data:
                    insert_sql = """
                    INSERT IGNORE INTO concept_daily_metrics 
                    (concept_name, trading_date, total_volume, stock_count, avg_volume, max_volume,
                     min_volume, volume_rank, stock_count_rank, is_new_high, new_high_days,
                     volume_change_pct, prev_day_volume, created_at)
                    VALUES 
                    """ + ','.join([
                        f"('{d['concept_name']}', '{d['trading_date']}', {d['total_volume']}, "
                        f"{d['stock_count']}, {d['avg_volume']}, {d['max_volume']}, {d['min_volume']}, "
                        f"{d['volume_rank']}, {d['stock_count_rank']}, {d['is_new_high']}, "
                        f"{d['new_high_days']}, {d['volume_change_pct']}, {d['prev_day_volume']}, "
                        f"'{d['created_at']}')"
                        for d in insert_data
                    ])
                    
                    self.db.execute(text(insert_sql))
                    self.db.commit()
                    
                    migrated += len(insert_data)
                    self.log_progress(f"å·²è¿ç§» {migrated}/{total_count} æ¡æ¦‚å¿µè®°å½•")
                
                offset += self.batch_size
            
            self.stats['concept_metrics'] = migrated
            
            # 3. æ‰¹é‡è®¡ç®—æ’åå’Œåˆ›æ–°é«˜
            self.calculate_concept_rankings()
            
            self.log_progress(f"æ¦‚å¿µæ±‡æ€»æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {migrated} æ¡è®°å½•")
            
        except Exception as e:
            logger.error(f"è¿ç§»æ¦‚å¿µæ±‡æ€»æ•°æ®å¤±è´¥: {e}")
            self.stats['errors'] += 1
            raise
    
    def migrate_stock_concept_relationships(self):
        """è¿ç§»è‚¡ç¥¨æ¦‚å¿µå…³ç³»æ•°æ®"""
        self.log_progress("å¼€å§‹è¿ç§»è‚¡ç¥¨æ¦‚å¿µå…³ç³»æ•°æ®...")
        
        try:
            # 1. è·å–ç°æœ‰æ•°æ®
            total_count = self.db.query(StockConceptRanking).count()
            self.log_progress(f"å‘ç° {total_count} æ¡è‚¡ç¥¨æ¦‚å¿µå…³ç³»è®°å½•")
            
            # 2. æ‰¹é‡è¿ç§»
            offset = 0
            migrated = 0
            
            while True:
                batch_data = self.db.query(StockConceptRanking).offset(offset).limit(self.batch_size).all()
                if not batch_data:
                    break
                
                insert_data = []
                for record in batch_data:
                    insert_data.append({
                        'stock_code': record.stock_code,
                        'concept_name': record.concept_name,
                        'trading_date': record.trading_date,
                        'trading_volume': record.trading_volume,
                        'concept_rank': record.concept_rank,
                        'volume_percentage': record.volume_percentage,
                        'concept_total_volume': record.concept_total_volume,
                        'concept_stock_count': 0,  # éœ€è¦é‡æ–°è®¡ç®—
                        'created_at': record.created_at or datetime.now()
                    })
                
                # æ‰¹é‡æ’å…¥
                if insert_data:
                    insert_sql = """
                    INSERT IGNORE INTO stock_concept_daily_snapshot 
                    (stock_code, concept_name, trading_date, trading_volume, concept_rank,
                     volume_percentage, concept_total_volume, concept_stock_count, created_at)
                    VALUES 
                    """ + ','.join([
                        f"('{d['stock_code']}', '{d['concept_name']}', '{d['trading_date']}', "
                        f"{d['trading_volume']}, {d['concept_rank']}, {d['volume_percentage']}, "
                        f"{d['concept_total_volume']}, {d['concept_stock_count']}, '{d['created_at']}')"
                        for d in insert_data
                    ])
                    
                    self.db.execute(text(insert_sql))
                    self.db.commit()
                    
                    migrated += len(insert_data)
                    self.log_progress(f"å·²è¿ç§» {migrated}/{total_count} æ¡å…³ç³»è®°å½•")
                
                offset += self.batch_size
            
            self.stats['stock_concept_snapshot'] = migrated
            self.log_progress(f"è‚¡ç¥¨æ¦‚å¿µå…³ç³»æ•°æ®è¿ç§»å®Œæˆï¼Œå…± {migrated} æ¡è®°å½•")
            
        except Exception as e:
            logger.error(f"è¿ç§»è‚¡ç¥¨æ¦‚å¿µå…³ç³»æ•°æ®å¤±è´¥: {e}")
            self.stats['errors'] += 1
            raise
    
    def calculate_daily_rankings(self):
        """æ‰¹é‡è®¡ç®—æ¯æ—¥è‚¡ç¥¨æ’å"""
        self.log_progress("å¼€å§‹è®¡ç®—æ¯æ—¥è‚¡ç¥¨æ’å...")
        
        try:
            # è·å–æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
            dates = self.db.execute(text("""
                SELECT DISTINCT trading_date FROM daily_trading_unified 
                WHERE rank_in_date = 0 
                ORDER BY trading_date DESC
            """)).fetchall()
            
            for date_row in dates:
                trading_date = date_row[0]
                
                # æ‰¹é‡æ›´æ–°æ’å
                update_sql = """
                UPDATE daily_trading_unified t1 
                JOIN (
                    SELECT stock_code, 
                           ROW_NUMBER() OVER (ORDER BY trading_volume DESC) as new_rank,
                           PERCENT_RANK() OVER (ORDER BY trading_volume DESC) * 100 as new_pct
                    FROM daily_trading_unified 
                    WHERE trading_date = :trading_date
                ) t2 ON t1.stock_code = t2.stock_code 
                SET t1.rank_in_date = t2.new_rank,
                    t1.volume_rank_pct = t2.new_pct
                WHERE t1.trading_date = :trading_date
                """
                
                self.db.execute(text(update_sql), {'trading_date': trading_date})
                self.db.commit()
                
                self.log_progress(f"å·²è®¡ç®— {trading_date} çš„è‚¡ç¥¨æ’å")
            
        except Exception as e:
            logger.error(f"è®¡ç®—æ¯æ—¥æ’åå¤±è´¥: {e}")
            raise
    
    def calculate_concept_rankings(self):
        """æ‰¹é‡è®¡ç®—æ¦‚å¿µæ’å"""
        self.log_progress("å¼€å§‹è®¡ç®—æ¦‚å¿µæ’å...")
        
        try:
            # è·å–æ‰€æœ‰äº¤æ˜“æ—¥æœŸ
            dates = self.db.execute(text("""
                SELECT DISTINCT trading_date FROM concept_daily_metrics 
                WHERE volume_rank = 0 
                ORDER BY trading_date DESC
            """)).fetchall()
            
            for date_row in dates:
                trading_date = date_row[0]
                
                # æ‰¹é‡æ›´æ–°æ’å
                update_sql = """
                UPDATE concept_daily_metrics c1 
                JOIN (
                    SELECT concept_name,
                           ROW_NUMBER() OVER (ORDER BY total_volume DESC) as vol_rank,
                           ROW_NUMBER() OVER (ORDER BY stock_count DESC) as count_rank
                    FROM concept_daily_metrics 
                    WHERE trading_date = :trading_date
                ) c2 ON c1.concept_name = c2.concept_name 
                SET c1.volume_rank = c2.vol_rank,
                    c1.stock_count_rank = c2.count_rank
                WHERE c1.trading_date = :trading_date
                """
                
                self.db.execute(text(update_sql), {'trading_date': trading_date})
                self.db.commit()
                
                self.log_progress(f"å·²è®¡ç®— {trading_date} çš„æ¦‚å¿µæ’å")
        
        except Exception as e:
            logger.error(f"è®¡ç®—æ¦‚å¿µæ’åå¤±è´¥: {e}")
            raise
    
    def get_stock_name(self, stock_code: str) -> str:
        """è·å–è‚¡ç¥¨åç§°"""
        try:
            # å°è¯•å¤šç§è‚¡ç¥¨ä»£ç æ ¼å¼åŒ¹é…
            possible_codes = [stock_code]
            if stock_code.startswith(('SH', 'SZ', 'BJ')):
                possible_codes.append(stock_code[2:])
            else:
                possible_codes.extend([f'SH{stock_code}', f'SZ{stock_code}', f'BJ{stock_code}'])
            
            for code in possible_codes:
                stock = self.db.query(Stock).filter(Stock.stock_code == code).first()
                if stock:
                    return stock.stock_name
            
            return f"è‚¡ç¥¨{stock_code}"  # é»˜è®¤åç§°
            
        except Exception:
            return f"è‚¡ç¥¨{stock_code}"
    
    def get_concept_count(self, stock_code: str, trading_date: date) -> int:
        """è·å–è‚¡ç¥¨æ¦‚å¿µæ•°é‡"""
        try:
            count = self.db.query(StockConceptRanking).filter(
                StockConceptRanking.stock_code == stock_code,
                StockConceptRanking.trading_date == trading_date
            ).count()
            return count
        except Exception:
            return 0
    
    def get_prev_day_volume(self, concept_name: str, trading_date: date) -> int:
        """è·å–å‰ä¸€æ—¥æ¦‚å¿µäº¤æ˜“é‡"""
        try:
            prev_date = trading_date - timedelta(days=1)
            prev_record = self.db.query(ConceptDailySummary).filter(
                ConceptDailySummary.concept_name == concept_name,
                ConceptDailySummary.trading_date == prev_date
            ).first()
            
            return prev_record.total_volume if prev_record else 0
            
        except Exception:
            return 0
    
    def create_today_cache(self):
        """åˆ›å»ºå½“å¤©æ•°æ®ç¼“å­˜"""
        self.log_progress("åˆ›å»ºå½“å¤©æ•°æ®ç¼“å­˜...")
        
        try:
            today = date.today()
            
            # æ¸…ç©ºç¼“å­˜è¡¨
            self.db.execute(text("TRUNCATE TABLE today_trading_cache"))
            
            # æ’å…¥å½“å¤©æ•°æ®
            insert_sql = """
            INSERT INTO today_trading_cache 
            (stock_code, stock_name, trading_volume, concept_count, rank_in_date)
            SELECT stock_code, stock_name, trading_volume, concept_count, rank_in_date
            FROM daily_trading_unified 
            WHERE trading_date = :today
            ORDER BY rank_in_date
            """
            
            result = self.db.execute(text(insert_sql), {'today': today})
            self.db.commit()
            
            self.log_progress(f"å·²åˆ›å»ºå½“å¤©ç¼“å­˜ï¼Œå…± {result.rowcount} æ¡è®°å½•")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå½“å¤©ç¼“å­˜å¤±è´¥: {e}")
            self.stats['errors'] += 1
    
    def validate_migration(self):
        """éªŒè¯è¿ç§»ç»“æœ"""
        self.log_progress("å¼€å§‹éªŒè¯è¿ç§»ç»“æœ...")
        
        try:
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            validations = []
            
            # 1. éªŒè¯æ¯æ—¥äº¤æ˜“æ•°æ®
            old_count = self.db.query(DailyTrading).count()
            new_count = self.db.execute(text("SELECT COUNT(*) FROM daily_trading_unified")).scalar()
            validations.append(('æ¯æ—¥äº¤æ˜“æ•°æ®', old_count, new_count, old_count == new_count))
            
            # 2. éªŒè¯æ¦‚å¿µæ±‡æ€»æ•°æ®
            old_count = self.db.query(ConceptDailySummary).count()
            new_count = self.db.execute(text("SELECT COUNT(*) FROM concept_daily_metrics")).scalar()
            validations.append(('æ¦‚å¿µæ±‡æ€»æ•°æ®', old_count, new_count, old_count == new_count))
            
            # 3. éªŒè¯è‚¡ç¥¨æ¦‚å¿µå…³ç³»æ•°æ®
            old_count = self.db.query(StockConceptRanking).count()
            new_count = self.db.execute(text("SELECT COUNT(*) FROM stock_concept_daily_snapshot")).scalar()
            validations.append(('è‚¡ç¥¨æ¦‚å¿µå…³ç³»', old_count, new_count, old_count == new_count))
            
            # è¾“å‡ºéªŒè¯ç»“æœ
            self.log_progress("è¿ç§»éªŒè¯ç»“æœ:")
            for desc, old_cnt, new_cnt, is_valid in validations:
                status = "âœ“" if is_valid else "âœ—"
                self.log_progress(f"{status} {desc}: {old_cnt} -> {new_cnt}")
                
            return all(v[3] for v in validations)
            
        except Exception as e:
            logger.error(f"éªŒè¯è¿ç§»ç»“æœå¤±è´¥: {e}")
            return False
    
    def run_migration(self):
        """æ‰§è¡Œå®Œæ•´è¿ç§»æµç¨‹"""
        self.log_progress("å¼€å§‹æ•°æ®åº“ä¼˜åŒ–è¿ç§»...")
        
        try:
            # 1. è¿ç§»æ¯æ—¥äº¤æ˜“æ•°æ®
            self.migrate_daily_trading_data()
            
            # 2. è¿ç§»æ¦‚å¿µæ±‡æ€»æ•°æ®
            self.migrate_concept_metrics()
            
            # 3. è¿ç§»è‚¡ç¥¨æ¦‚å¿µå…³ç³»æ•°æ®
            self.migrate_stock_concept_relationships()
            
            # 4. åˆ›å»ºå½“å¤©ç¼“å­˜
            self.create_today_cache()
            
            # 5. éªŒè¯è¿ç§»ç»“æœ
            is_valid = self.validate_migration()
            
            # 6. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            total_time = time.time() - self.start_time
            self.log_progress(f"è¿ç§»å®Œæˆï¼æ€»è€—æ—¶: {total_time:.1f}ç§’")
            self.log_progress(f"è¿ç§»ç»Ÿè®¡: {self.stats}")
            
            if is_valid and self.stats['errors'] == 0:
                self.log_progress("âœ“ è¿ç§»æˆåŠŸï¼æ•°æ®åº“ä¼˜åŒ–å®Œæˆï¼Œé¢„æœŸæŸ¥è¯¢æ€§èƒ½æå‡50-200å€")
                return True
            else:
                self.log_progress("âœ— è¿ç§»å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
                return False
                
        except Exception as e:
            logger.error(f"è¿ç§»è¿‡ç¨‹å¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("=== æ•°æ®åº“ä¼˜åŒ–è¿ç§»å·¥å…· v2.6.4 ===")
    print("æ­¤å·¥å…·å°†ç°æœ‰æ•°æ®è¿ç§»åˆ°ä¼˜åŒ–åçš„è¡¨ç»“æ„")
    print("é¢„æœŸæ€§èƒ½æå‡ï¼šæŸ¥è¯¢é€Ÿåº¦æå‡50-200å€")
    print()
    
    # ç¡®è®¤æ“ä½œ
    confirm = input("ç¡®è®¤å¼€å§‹è¿ç§»ï¼Ÿ(yes/no): ").lower().strip()
    if confirm != 'yes':
        print("è¿ç§»å·²å–æ¶ˆ")
        return
    
    # æ‰§è¡Œè¿ç§»
    with DatabaseMigration() as migration:
        success = migration.run_migration()
        
        if success:
            print("\nğŸ‰ æ•°æ®åº“ä¼˜åŒ–è¿ç§»æˆåŠŸå®Œæˆï¼")
            print("ğŸ“Š ç°åœ¨å¯ä»¥äº«å—æé€ŸæŸ¥è¯¢ä½“éªŒäº†")
            print("ğŸ”§ å»ºè®®æ‰§è¡Œ: CALL sp_analyze_query_performance(CURDATE()) æµ‹è¯•æ€§èƒ½")
        else:
            print("\nâŒ è¿ç§»è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜")
            print("ğŸ“‹ è¯·æŸ¥çœ‹ migration.log è·å–è¯¦ç»†ä¿¡æ¯")
            return 1
    
    return 0

if __name__ == "__main__":
    exit(main())