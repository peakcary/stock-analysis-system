#!/usr/bin/env python3
"""
æ¨¡å‹å®šä¹‰åŒæ­¥è„šæœ¬
ç”¨äºåœ¨æ•°æ®åº“ä¼˜åŒ–éƒ¨ç½²åè‡ªåŠ¨åŒæ­¥SQLAlchemyæ¨¡å‹å®šä¹‰

å½“æ•°æ®åº“è¡¨ç»“æ„é€šè¿‡SQLè„šæœ¬ä¿®æ”¹åï¼Œè¿™ä¸ªè„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹å·®å¼‚å¹¶æ›´æ–°æ¨¡å‹æ–‡ä»¶
"""

import os
import sys
import re
from pathlib import Path
from sqlalchemy import create_engine, text, inspect
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
script_dir = Path(__file__).parent
project_root = script_dir.parent.parent
sys.path.append(str(project_root / "backend"))

def get_database_url():
    """è·å–æ•°æ®åº“è¿æ¥URL"""
    try:
        from app.core.config import settings
        return settings.SQLALCHEMY_DATABASE_URI
    except ImportError:
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        return "mysql+pymysql://root:123456@localhost:3306/stock_analysis_dev"

def analyze_table_structure(engine, table_name):
    """åˆ†ææ•°æ®åº“è¡¨ç»“æ„"""
    with engine.connect() as conn:
        try:
            result = conn.execute(text(f"DESCRIBE {table_name}"))
            columns = []
            for row in result:
                columns.append({
                    'name': row[0],
                    'type': row[1],
                    'nullable': row[2] == 'YES',
                    'key': row[3],
                    'default': row[4],
                    'extra': row[5] if len(row) > 5 else ''
                })
            return columns
        except Exception as e:
            print(f"âŒ åˆ†æè¡¨ {table_name} å¤±è´¥: {e}")
            return []

def generate_sqlalchemy_field(column):
    """å°†æ•°æ®åº“å­—æ®µè½¬æ¢ä¸ºSQLAlchemyå­—æ®µå®šä¹‰"""
    field_type = column['type'].lower()

    # æ˜ å°„æ•°æ®åº“ç±»å‹åˆ°SQLAlchemyç±»å‹
    type_mapping = {
        'int': 'Integer',
        'varchar': 'String',
        'date': 'Date',
        'datetime': 'DateTime',
        'timestamp': 'DateTime',
        'bigint': 'BigInteger',
        'text': 'Text',
        'decimal': 'DECIMAL',
        'float': 'Float',
        'boolean': 'Boolean',
        'tinyint(1)': 'Boolean'
    }

    # æå–ç±»å‹åç§°ï¼ˆå»æ‰é•¿åº¦ä¿¡æ¯ï¼‰
    type_name = re.match(r'([a-z]+)', field_type).group(1)
    sqlalchemy_type = type_mapping.get(type_name, 'String')

    # å¤„ç†å­—ç¬¦ä¸²é•¿åº¦
    if 'varchar' in field_type:
        length_match = re.search(r'varchar\((\d+)\)', field_type)
        if length_match:
            length = length_match.group(1)
            sqlalchemy_type = f'String({length})'

    # æ„å»ºå­—æ®µå®šä¹‰
    field_definition = f"Column({sqlalchemy_type}"

    # æ·»åŠ çº¦æŸ
    if column['key'] == 'PRI':
        field_definition += ", primary_key=True"
    if not column['nullable']:
        field_definition += ", nullable=False"
    if column['key'] == 'MUL':
        field_definition += ", index=True"
    if column['extra'] == 'auto_increment':
        field_definition += ", autoincrement=True"
    if column['default'] and column['default'] != 'NULL':
        if 'timestamp' in field_type.lower() or 'datetime' in field_type.lower():
            if 'current_timestamp' in str(column['default']).lower():
                field_definition += ", default=datetime.datetime.utcnow"
        else:
            field_definition += f", default={repr(column['default'])}"

    # æ·»åŠ æ³¨é‡Š
    field_definition += f', comment="{column["name"]}"'

    field_definition += ")"

    return f"    {column['name']} = {field_definition}"

def update_model_file(model_file_path, table_name, columns):
    """æ›´æ–°æ¨¡å‹æ–‡ä»¶"""
    if not os.path.exists(model_file_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file_path}")
        return False

    # è¯»å–ç°æœ‰æ–‡ä»¶
    with open(model_file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # æŸ¥æ‰¾ç±»å®šä¹‰
    class_pattern = rf'class\s+\w+.*?__tablename__\s*=\s*["\']({table_name})["\'].*?(?=class|\Z)'
    match = re.search(class_pattern, content, re.DOTALL)

    if not match:
        print(f"âŒ åœ¨ {model_file_path} ä¸­æœªæ‰¾åˆ°è¡¨ {table_name} çš„æ¨¡å‹å®šä¹‰")
        return False

    # ç”Ÿæˆæ–°çš„å­—æ®µå®šä¹‰
    new_fields = []
    for column in columns:
        if column['name'] != 'id':  # idå­—æ®µé€šå¸¸å·²ç»å­˜åœ¨
            new_fields.append(generate_sqlalchemy_field(column))

    # æå–ç°æœ‰çš„å­—æ®µéƒ¨åˆ†
    class_content = match.group(0)

    # æŸ¥æ‰¾å­—æ®µå®šä¹‰åŒºåŸŸ
    field_pattern = r'(\s+)(\w+)\s*=\s*Column\([^)]+\)'
    existing_fields = re.findall(field_pattern, class_content)

    if existing_fields:
        # æ›´æ–°å­—æ®µå®šä¹‰
        updated_class = class_content
        for field in new_fields:
            field_name = field.split(' = ')[0].strip()
            field_pattern = rf'(\s+){field_name}\s*=\s*Column\([^)]+\)'
            if re.search(field_pattern, updated_class):
                # æ›¿æ¢ç°æœ‰å­—æ®µ
                updated_class = re.sub(field_pattern, field, updated_class)
            else:
                # æ·»åŠ æ–°å­—æ®µï¼ˆåœ¨ç¬¬ä¸€ä¸ªå­—æ®µåï¼‰
                first_field_match = re.search(r'(\s+\w+\s*=\s*Column\([^)]+\))', updated_class)
                if first_field_match:
                    insertion_point = first_field_match.end()
                    updated_class = updated_class[:insertion_point] + '\n' + field + updated_class[insertion_point:]

        # æ›¿æ¢åŸå†…å®¹
        new_content = content.replace(class_content, updated_class)

        # å†™å›æ–‡ä»¶
        with open(model_file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

        print(f"âœ… å·²æ›´æ–°æ¨¡å‹æ–‡ä»¶: {model_file_path}")
        return True
    else:
        print(f"âŒ æ— æ³•è§£æ {model_file_path} ä¸­çš„å­—æ®µå®šä¹‰")
        return False

def sync_models(database_url, dry_run=False):
    """åŒæ­¥æ‰€æœ‰æ¨¡å‹å®šä¹‰"""
    print("ğŸ”„ å¼€å§‹åŒæ­¥æ¨¡å‹å®šä¹‰...")

    # è¿æ¥æ•°æ®åº“
    engine = create_engine(database_url)

    # éœ€è¦åŒæ­¥çš„è¡¨å’Œå¯¹åº”çš„æ¨¡å‹æ–‡ä»¶
    tables_to_sync = {
        'daily_trading': 'backend/app/models/daily_trading.py',
        'concept_daily_summary': 'backend/app/models/daily_trading.py',
        'stock_concept_ranking': 'backend/app/models/daily_trading.py',
        'concept_high_record': 'backend/app/models/daily_trading.py',
        'txt_import_record': 'backend/app/models/daily_trading.py'
    }

    success_count = 0
    total_count = len(tables_to_sync)

    for table_name, model_file in tables_to_sync.items():
        print(f"\nğŸ“Š åŒæ­¥è¡¨: {table_name}")

        # åˆ†æè¡¨ç»“æ„
        columns = analyze_table_structure(engine, table_name)
        if not columns:
            continue

        print(f"  å‘ç° {len(columns)} ä¸ªå­—æ®µ")

        if dry_run:
            print("  [DRY RUN] æ¨¡æ‹ŸåŒæ­¥ï¼Œä¸ä¿®æ”¹æ–‡ä»¶")
            for column in columns:
                print(f"    - {column['name']}: {column['type']}")
        else:
            # æ›´æ–°æ¨¡å‹æ–‡ä»¶
            model_path = project_root / model_file
            if update_model_file(str(model_path), table_name, columns):
                success_count += 1

    print(f"\nğŸ‰ åŒæ­¥å®Œæˆ: {success_count}/{total_count} ä¸ªè¡¨æˆåŠŸåŒæ­¥")

    if success_count == total_count:
        print("âœ… æ‰€æœ‰æ¨¡å‹å®šä¹‰å·²åŒæ­¥")
        return True
    else:
        print(f"âš ï¸  {total_count - success_count} ä¸ªè¡¨åŒæ­¥å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥")
        return False

def main():
    parser = argparse.ArgumentParser(description='åŒæ­¥SQLAlchemyæ¨¡å‹å®šä¹‰')
    parser.add_argument('--database-url', help='æ•°æ®åº“è¿æ¥URL')
    parser.add_argument('--dry-run', action='store_true', help='ä»…é¢„è§ˆï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶')
    parser.add_argument('--table', help='åªåŒæ­¥æŒ‡å®šè¡¨')

    args = parser.parse_args()

    # è·å–æ•°æ®åº“URL
    database_url = args.database_url or get_database_url()
    print(f"ğŸ”— æ•°æ®åº“è¿æ¥: {database_url.split('@')[1] if '@' in database_url else database_url}")

    try:
        success = sync_models(database_url, args.dry_run)
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"âŒ åŒæ­¥å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()