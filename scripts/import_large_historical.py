#!/usr/bin/env python3
"""
å¤§æ–‡ä»¶å†å²æ•°æ®å¯¼å…¥è„šæœ¬
æ”¯æŒå¤„ç†åŒ…å«å¤šä¸ªæ—¥æœŸçš„å¤§å‹TXTæ–‡ä»¶ï¼Œè‡ªåŠ¨æŒ‰æ—¥æœŸåˆ†ç»„å¹¶é€æ—¥å¯¼å…¥
"""

# å¿…é¡»åœ¨å¯¼å…¥ä»»ä½•SQLAlchemyç›¸å…³æ¨¡å—ä¹‹å‰å®Œå…¨ç¦ç”¨SQLæ—¥å¿—
import logging
import os

# è®¾ç½®ç¯å¢ƒå˜é‡å®Œå…¨ç¦ç”¨SQLAlchemyæ—¥å¿—
os.environ['SQLALCHEMY_SILENCE_UBER_WARNING'] = '1'

# é…ç½®æ—¥å¿—ç³»ç»Ÿ
logging.basicConfig(level=logging.CRITICAL, format='')

# è·å–æ ¹æ—¥å¿—å™¨å¹¶ç¦ç”¨æ‰€æœ‰å¤„ç†å™¨
root_logger = logging.getLogger()
for handler in root_logger.handlers[:]:
    root_logger.removeHandler(handler)

# åˆ›å»ºç©ºçš„å¤„ç†å™¨é¿å…æ—¥å¿—è¾“å‡º
class NullHandler(logging.Handler):
    def emit(self, record):
        pass

null_handler = NullHandler()
root_logger.addHandler(null_handler)
root_logger.setLevel(logging.CRITICAL)

# å½»åº•ç¦ç”¨SQLAlchemyç›¸å…³æ—¥å¿—
for logger_name in [
    'sqlalchemy', 'sqlalchemy.engine', 'sqlalchemy.pool',
    'sqlalchemy.orm', 'sqlalchemy.dialects', 'sqlalchemy.engine.Engine'
]:
    logger = logging.getLogger(logger_name)
    logger.setLevel(logging.CRITICAL)
    logger.disabled = True
    logger.propagate = False
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)

# æŠ‘åˆ¶è­¦å‘Šä¿¡æ¯
import warnings
warnings.filterwarnings("ignore")

import os
import sys
import time
import argparse
from datetime import datetime
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Optional

# æ·»åŠ åç«¯ç›®å½•åˆ°è·¯å¾„
script_dir = Path(__file__).parent
backend_dir = script_dir.parent / "backend"
sys.path.insert(0, str(backend_dir))

from app.core.database import get_db
from app.services.historical_txt_import import HistoricalTxtImportService


def parse_large_txt_by_date(file_path: str, encoding: str = 'utf-8', quiet: bool = False, ignore_errors: bool = False, _retry_count: int = 0) -> Dict[str, List[str]]:
    """æŒ‰æ—¥æœŸåˆ†ç»„è§£æå¤§å‹TXTæ–‡ä»¶"""
    if not quiet:
        print(f"ğŸ“ å¼€å§‹è§£ææ–‡ä»¶: {file_path}")

    date_groups = defaultdict(list)
    total_lines = 0
    valid_lines = 0
    error_lines = 0

    file_size = os.path.getsize(file_path)
    file_size_mb = file_size / 1024 / 1024

    if not quiet:
        print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")

    start_time = time.time()

    try:
        with open(file_path, 'r', encoding=encoding) as file:
            for line_num, line in enumerate(file, 1):
                total_lines += 1

                # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯10000è¡Œï¼‰
                if not quiet and total_lines % 10000 == 0:
                    elapsed = time.time() - start_time
                    print(f"ğŸ“ˆ å·²å¤„ç† {total_lines:,} è¡Œï¼Œç”¨æ—¶ {elapsed:.1f}s")

                line = line.strip()
                if not line:
                    continue

                try:
                    parts = line.split('\t')
                    if len(parts) != 3:
                        error_lines += 1
                        continue

                    stock_code, date_str, volume_str = parts

                    # éªŒè¯æ—¥æœŸæ ¼å¼
                    datetime.strptime(date_str, '%Y-%m-%d')

                    # éªŒè¯äº¤æ˜“é‡
                    float(volume_str)

                    date_groups[date_str].append(line)
                    valid_lines += 1

                except (ValueError, IndexError) as e:
                    error_lines += 1
                    # å¦‚æœä¸å¿½ç•¥é”™è¯¯ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                    if not ignore_errors and not quiet:
                        if error_lines <= 5:
                            print(f"âš ï¸  ç¬¬{line_num}è¡Œæ ¼å¼é”™è¯¯: {line[:50]}...")
                        elif error_lines == 6:
                            print(f"âš ï¸  ... è¿˜æœ‰æ›´å¤šæ ¼å¼é”™è¯¯ï¼Œå°†è‡ªåŠ¨è·³è¿‡")

                    # å¦‚æœä¸å¿½ç•¥é”™è¯¯ä¸”é”™è¯¯å¤ªå¤šï¼Œç»ˆæ­¢å¤„ç†
                    if not ignore_errors and error_lines > 1000:
                        print(f"âŒ é”™è¯¯è¡Œæ•°è¿‡å¤š ({error_lines})ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
                        break

    except UnicodeDecodeError:
        if _retry_count == 0 and encoding.lower() != 'gbk':
            print(f"âŒ ç¼–ç é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨GBKç¼–ç ...")
            return parse_large_txt_by_date(file_path, 'gbk', quiet, ignore_errors, 1)
        else:
            print(f"âŒ ç¼–ç é”™è¯¯ï¼Œæ— æ³•è§£ææ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ç¼–ç ")
            return {}

    elapsed = time.time() - start_time

    if not quiet:
        print(f"\nâœ… æ–‡ä»¶è§£æå®Œæˆ:")
        print(f"   ğŸ“ æ€»è¡Œæ•°: {total_lines:,}")
        print(f"   âœ… æœ‰æ•ˆè¡Œæ•°: {valid_lines:,}")
        print(f"   âŒ é”™è¯¯è¡Œæ•°: {error_lines:,}")
        print(f"   ğŸ“… å‘ç°æ—¥æœŸ: {len(date_groups)} ä¸ª")
        print(f"   â±ï¸  è§£æç”¨æ—¶: {elapsed:.2f}s")

    return dict(date_groups)


def import_date_groups(date_groups: Dict[str, List[str]], imported_by: str = "script", quiet: bool = False):
    """æŒ‰æ—¥æœŸåˆ†ç»„å¯¼å…¥æ•°æ®"""
    if not quiet:
        print(f"\nğŸš€ å¼€å§‹æ•°æ®å¯¼å…¥...")

    # æŒ‰æ—¥æœŸæ’åº
    sorted_dates = sorted(date_groups.keys())
    total_dates = len(sorted_dates)

    if not quiet:
        print(f"ğŸ“… å°†æŒ‰æ—¶é—´é¡ºåºå¯¼å…¥ {total_dates} ä¸ªæ—¥æœŸçš„æ•°æ®")

    # è·å–æ•°æ®åº“ä¼šè¯
    db = next(get_db())
    historical_service = HistoricalTxtImportService(db)
    txt_service = historical_service.txt_service

    success_count = 0
    failed_count = 0
    total_records = 0
    failed_dates = []

    start_time = time.time()

    for i, date_str in enumerate(sorted_dates, 1):
        date_lines = date_groups[date_str]

        print(f"\nğŸ“Š [{i}/{total_dates}] æ­£åœ¨å¯¼å…¥ {date_str} ({len(date_lines):,} æ¡è®°å½•)")

        try:
            # æ„é€ å•æ—¥æ•°æ®å†…å®¹
            single_date_content = '\n'.join(date_lines)

            # ä½¿ç”¨TXTå¯¼å…¥æœåŠ¡ï¼ˆä¼šåˆ›å»ºå¯¼å…¥è®°å½•ï¼‰
            result = txt_service.import_daily_trading(
                txt_content=single_date_content,
                filename=f"large_file_{date_str}.txt",
                file_size=len(single_date_content.encode('utf-8')),
                imported_by=imported_by
            )

            if result["success"]:
                success_count += 1
                records_count = result["stats"]["trading_data_count"]
                total_records += records_count
                print(f"   âœ… å¯¼å…¥æˆåŠŸ: {records_count:,} æ¡è®°å½•")
            else:
                failed_count += 1
                failed_dates.append(date_str)
                print(f"   âŒ å¯¼å…¥å¤±è´¥: {result['message']}")

        except Exception as e:
            failed_count += 1
            failed_dates.append(date_str)
            print(f"   âŒ å¯¼å…¥å¼‚å¸¸: {str(e)}")

        # æ˜¾ç¤ºè¿›åº¦
        progress = (i / total_dates) * 100
        elapsed = time.time() - start_time
        avg_time = elapsed / i
        eta = avg_time * (total_dates - i)

        print(f"   ğŸ“ˆ è¿›åº¦: {progress:.1f}% | ç”¨æ—¶: {elapsed:.1f}s | é¢„è®¡å‰©ä½™: {eta:.1f}s")

    # å…³é—­æ•°æ®åº“è¿æ¥
    db.close()

    total_time = time.time() - start_time

    print(f"\nğŸ‰ å¯¼å…¥å®Œæˆ!")
    print(f"   ğŸ“… æ€»æ—¥æœŸæ•°: {total_dates}")
    print(f"   âœ… æˆåŠŸ: {success_count}")
    print(f"   âŒ å¤±è´¥: {failed_count}")
    print(f"   ğŸ“ æ€»è®°å½•æ•°: {total_records:,}")
    print(f"   â±ï¸  æ€»ç”¨æ—¶: {total_time:.2f}s")

    if failed_dates:
        print(f"\nâŒ å¤±è´¥çš„æ—¥æœŸ:")
        for date in failed_dates:
            print(f"   - {date}")

    return {
        "total_dates": total_dates,
        "success_count": success_count,
        "failed_count": failed_count,
        "total_records": total_records,
        "failed_dates": failed_dates,
        "total_time": total_time
    }


def main():
    parser = argparse.ArgumentParser(description='å¯¼å…¥å¤§å‹å†å²TXTæ–‡ä»¶')
    parser.add_argument('file_path', help='TXTæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--encoding', default='utf-8', help='æ–‡ä»¶ç¼–ç  (é»˜è®¤: utf-8)')
    parser.add_argument('--imported-by', default='script', help='å¯¼å…¥è€…æ ‡è¯†')
    parser.add_argument('--preview-only', action='store_true', help='ä»…é¢„è§ˆï¼Œä¸å¯¼å…¥')
    parser.add_argument('--yes', '-y', action='store_true', help='è‡ªåŠ¨ç¡®è®¤å¯¼å…¥ï¼Œä¸è¯¢é—®')
    parser.add_argument('--quiet', '-q', action='store_true', help='é™é»˜æ¨¡å¼ï¼Œå‡å°‘è¾“å‡ºä¿¡æ¯')
    parser.add_argument('--ignore-errors', action='store_true', help='å¿½ç•¥æ•°æ®æ ¼å¼é”™è¯¯ï¼Œç»§ç»­å¤„ç†')

    args = parser.parse_args()

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.file_path}")
        return 1

    print(f"ğŸš€ å¤§æ–‡ä»¶å†å²æ•°æ®å¯¼å…¥å·¥å…·")
    print(f"ğŸ“ æ–‡ä»¶: {args.file_path}")
    print(f"ğŸ”¤ ç¼–ç : {args.encoding}")
    print(f"ğŸ‘¤ å¯¼å…¥è€…: {args.imported_by}")
    print(f"={'='*50}")

    try:
        # è§£ææ–‡ä»¶
        date_groups = parse_large_txt_by_date(args.file_path, args.encoding, args.quiet, args.ignore_errors)

        if not date_groups:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
            return 1

        # æ˜¾ç¤ºé¢„è§ˆä¿¡æ¯
        print(f"\nğŸ“‹ æ•°æ®é¢„è§ˆ:")
        for date_str in sorted(list(date_groups.keys())[:10]):  # æ˜¾ç¤ºå‰10ä¸ªæ—¥æœŸ
            count = len(date_groups[date_str])
            print(f"   {date_str}: {count:,} æ¡è®°å½•")

        if len(date_groups) > 10:
            print(f"   ... è¿˜æœ‰ {len(date_groups) - 10} ä¸ªæ—¥æœŸ")

        if args.preview_only:
            print("\nğŸ‘€ é¢„è§ˆæ¨¡å¼ï¼Œä¸æ‰§è¡Œå¯¼å…¥")
            return 0

        # ç¡®è®¤å¯¼å…¥
        if args.yes:
            print(f"\nâœ… è‡ªåŠ¨ç¡®è®¤å¯¼å…¥ {len(date_groups)} ä¸ªæ—¥æœŸçš„æ•°æ®")
        else:
            response = input(f"\nâ“ ç¡®è®¤å¯¼å…¥ {len(date_groups)} ä¸ªæ—¥æœŸçš„æ•°æ®å—? (y/N): ")
            if response.lower() != 'y':
                print("âŒ å–æ¶ˆå¯¼å…¥")
                return 0

        # æ‰§è¡Œå¯¼å…¥
        result = import_date_groups(date_groups, args.imported_by, args.quiet)

        if result["failed_count"] > 0:
            return 1

        return 0

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())