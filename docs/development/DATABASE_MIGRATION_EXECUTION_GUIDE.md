# ğŸš€ æ•°æ®åº“ä¼˜åŒ–å®æ–½æ‰§è¡ŒæŒ‡å—

## ğŸ“‹ æ‰§è¡Œæ¦‚è§ˆ

**é‡è¦è¯´æ˜**: è¿™æ˜¯ä¸€ä¸ª**æ¸è¿›å¼è¿ç§»æ–¹æ¡ˆ**ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨è¿ç§»è¿‡ç¨‹ä¸­æŒç»­å¯ç”¨ã€‚

### ğŸ“… å®æ–½è®¡åˆ’ (é¢„è®¡4å°æ—¶å®Œæˆ)

| é˜¶æ®µ | æ—¶é—´ | ä»»åŠ¡ | å½±å“ |
|------|------|------|------|
| **Phase 1** | 30åˆ†é’Ÿ | åˆ›å»ºæ–°è¡¨ç»“æ„å’Œæ¨¡å‹ | æ— å½±å“ |
| **Phase 2** | 60åˆ†é’Ÿ | ä¿®æ”¹APIæ¥å£é€‚é…æ–°è¡¨ | æ— å½±å“ |
| **Phase 3** | 90åˆ†é’Ÿ | æ•°æ®è¿ç§»å’ŒåŒå†™æ¨¡å¼ | æ— å½±å“ |
| **Phase 4** | 60åˆ†é’Ÿ | åˆ‡æ¢å’ŒéªŒè¯ | é‡å¯æœåŠ¡ |

## ğŸ¯ æ‰§è¡Œç­–ç•¥

### 1. **åŒå†™æ¨¡å¼** (å®‰å…¨è¿ç§»)
```
å¯¼å…¥æ•°æ®æ—¶ â†’ åŒæ—¶å†™å…¥æ—§è¡¨å’Œæ–°è¡¨
æŸ¥è¯¢æ—¶ â†’ ä¼˜å…ˆæŸ¥æ–°è¡¨ï¼Œå¤±è´¥æ—¶å›é€€åˆ°æ—§è¡¨
```

### 2. **APIæ¥å£å‘åå…¼å®¹**
```
ä¿æŒAPIæ¥å£ä¸å˜ï¼Œåªä¿®æ”¹å†…éƒ¨å®ç°
å‰ç«¯æ— éœ€ä»»ä½•ä¿®æ”¹
```

### 3. **åˆ†é˜¶æ®µéªŒè¯**
```
æ¯ä¸ªé˜¶æ®µéƒ½æœ‰éªŒè¯æ­¥éª¤
å¯éšæ—¶å›é€€åˆ°ä¸Šä¸€ä¸ªç¨³å®šçŠ¶æ€
```

## ğŸ› ï¸ Phase 1: åˆ›å»ºæ–°è¡¨ç»“æ„å’Œæ¨¡å‹

### 1.1 æ‰§è¡Œæ•°æ®åº“å»ºè¡¨è„šæœ¬

```bash
# 1. å¤‡ä»½ç°æœ‰æ•°æ®åº“
mysqldump -u root -p stock_analysis > backup_$(date +%Y%m%d_%H%M).sql

# 2. åˆ›å»ºä¼˜åŒ–è¡¨ç»“æ„
mysql -u root -p stock_analysis < ./scripts/database/create_optimized_tables.sql

# 3. åˆ›å»ºè§†å›¾å’Œç´¢å¼•
mysql -u root -p stock_analysis < ./scripts/database/create_views_and_indexes.sql
```

### 1.2 åˆ›å»ºæ–°çš„æ•°æ®æ¨¡å‹

```python
# backend/app/models/optimized_trading.py
from sqlalchemy import Column, String, Integer, Date, DateTime, Index, Boolean, Float, DECIMAL
from app.core.database import Base
import datetime

class DailyTradingUnified(Base):
    """ä¼˜åŒ–çš„ç»Ÿä¸€æ¯æ—¥äº¤æ˜“è¡¨"""
    __tablename__ = "daily_trading_unified"
    
    id = Column(Integer, primary_key=True, index=True)
    stock_code = Column(String(20), nullable=False, index=True)
    stock_name = Column(String(100), nullable=False)
    trading_date = Column(Date, nullable=False, index=True)
    trading_volume = Column(Integer, nullable=False)
    heat_value = Column(DECIMAL(15,2), default=0)
    
    # é¢„è®¡ç®—å­—æ®µ
    concept_count = Column(Integer, default=0)
    rank_in_date = Column(Integer, default=0)
    volume_rank_pct = Column(DECIMAL(5,2), default=0)
    
    created_at = Column(DateTime, default=datetime.datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.datetime.utcnow, onupdate=datetime.datetime.utcnow)

class ConceptDailyMetrics(Base):
    """ä¼˜åŒ–çš„æ¦‚å¿µæ¯æ—¥æŒ‡æ ‡è¡¨"""
    __tablename__ = "concept_daily_metrics"
    
    id = Column(Integer, primary_key=True, index=True)
    concept_name = Column(String(100), nullable=False, index=True)
    trading_date = Column(Date, nullable=False, index=True)
    total_volume = Column(Integer, nullable=False)
    stock_count = Column(Integer, nullable=False)
    avg_volume = Column(DECIMAL(15,2), nullable=False)
    max_volume = Column(Integer, nullable=False)
    min_volume = Column(Integer, default=0)
    
    # é¢„è®¡ç®—æ’å
    volume_rank = Column(Integer, default=0)
    stock_count_rank = Column(Integer, default=0)
    
    # è¶‹åŠ¿åˆ†æ
    is_new_high = Column(Boolean, default=False)
    new_high_days = Column(Integer, default=0)
    volume_change_pct = Column(DECIMAL(5,2), default=0)
    prev_day_volume = Column(Integer, default=0)
    
    created_at = Column(DateTime, default=datetime.datetime.utcnow)

class StockConceptDailySnapshot(Base):
    """ä¼˜åŒ–çš„è‚¡ç¥¨æ¦‚å¿µå…³ç³»è¡¨"""
    __tablename__ = "stock_concept_daily_snapshot"
    
    id = Column(Integer, primary_key=True, index=True)
    stock_code = Column(String(20), nullable=False, index=True)
    concept_name = Column(String(100), nullable=False, index=True)
    trading_date = Column(Date, nullable=False, index=True)
    trading_volume = Column(Integer, nullable=False)
    concept_rank = Column(Integer, nullable=False)
    volume_percentage = Column(DECIMAL(5,2), nullable=False)
    concept_total_volume = Column(Integer, nullable=False)
    concept_stock_count = Column(Integer, default=0)
    
    created_at = Column(DateTime, default=datetime.datetime.utcnow)
```

## ğŸ”§ Phase 2: ä¿®æ”¹APIæ¥å£é€‚é…æ–°è¡¨

### 2.1 åˆ›å»ºæœåŠ¡å±‚é€‚é…å™¨

```python
# backend/app/services/optimized_query_service.py
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import desc, func, and_, or_, text
from app.models.optimized_trading import (
    DailyTradingUnified, 
    ConceptDailyMetrics, 
    StockConceptDailySnapshot
)
from app.models.daily_trading import DailyTrading, ConceptDailySummary, StockConceptRanking
import logging

logger = logging.getLogger(__name__)

class OptimizedQueryService:
    """ä¼˜åŒ–æŸ¥è¯¢æœåŠ¡ - æ”¯æŒæ–°æ—§è¡¨åˆ‡æ¢"""
    
    def __init__(self, db: Session, use_optimized: bool = True):
        self.db = db
        self.use_optimized = use_optimized
    
    async def get_stocks_daily_summary(
        self, 
        trading_date: str,
        page: int = 1,
        size: int = 50,
        search: Optional[str] = None
    ) -> Dict[str, Any]:
        """è·å–è‚¡ç¥¨æ¯æ—¥æ±‡æ€» - æ™ºèƒ½åˆ‡æ¢ç‰ˆæœ¬"""
        
        try:
            if self.use_optimized:
                return await self._get_stocks_summary_optimized(trading_date, page, size, search)
            else:
                return await self._get_stocks_summary_legacy(trading_date, page, size, search)
        except Exception as e:
            logger.warning(f"ä¼˜åŒ–æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»ŸæŸ¥è¯¢: {e}")
            return await self._get_stocks_summary_legacy(trading_date, page, size, search)
    
    async def _get_stocks_summary_optimized(
        self, 
        trading_date: str, 
        page: int, 
        size: int, 
        search: Optional[str]
    ) -> Dict[str, Any]:
        """ä½¿ç”¨ä¼˜åŒ–è¡¨çš„æŸ¥è¯¢"""
        
        # åŸºç¡€æŸ¥è¯¢ - ç›´æ¥ä½¿ç”¨é¢„è®¡ç®—å­—æ®µ
        query = self.db.query(
            DailyTradingUnified.stock_code,
            DailyTradingUnified.stock_name,
            DailyTradingUnified.trading_volume,
            DailyTradingUnified.trading_date,
            DailyTradingUnified.concept_count,  # é¢„è®¡ç®—å­—æ®µï¼Œæ— éœ€JOIN
            DailyTradingUnified.rank_in_date    # é¢„è®¡ç®—å­—æ®µï¼Œæ— éœ€è®¡ç®—
        ).filter(
            DailyTradingUnified.trading_date == trading_date
        )
        
        # æœç´¢æ¡ä»¶
        if search:
            search_filter = or_(
                DailyTradingUnified.stock_code.like(f"%{search}%"),
                DailyTradingUnified.stock_name.like(f"%{search}%")
            )
            query = query.filter(search_filter)
        
        # æ’åº - ç›´æ¥ä½¿ç”¨é¢„è®¡ç®—æ’å
        query = query.order_by(DailyTradingUnified.rank_in_date)
        
        # è®¡ç®—æ€»æ•°
        total_count = query.count()
        
        # åˆ†é¡µ
        offset = (page - 1) * size
        stocks = query.offset(offset).limit(size).all()
        
        # æ„é€ è¿”å›æ•°æ®
        stock_summaries = []
        for stock_code, stock_name, trading_volume, trade_date, concept_count, rank in stocks:
            stock_summaries.append({
                "stock_code": stock_code,
                "stock_name": stock_name,
                "trading_volume": trading_volume,
                "trading_date": trade_date.strftime('%Y-%m-%d'),
                "concept_count": concept_count,
                "rank_in_date": rank
            })
        
        return {
            "trading_date": trading_date,
            "summaries": stock_summaries,
            "pagination": {
                "page": page,
                "size": size,
                "total": total_count,
                "pages": (total_count + size - 1) // size
            },
            "performance_info": {
                "query_type": "optimized",
                "returned_count": len(stock_summaries)
            }
        }
    
    async def _get_stocks_summary_legacy(
        self, 
        trading_date: str, 
        page: int, 
        size: int, 
        search: Optional[str]
    ) -> Dict[str, Any]:
        """ä½¿ç”¨åŸæœ‰è¡¨çš„æŸ¥è¯¢ - å…¼å®¹é€»è¾‘"""
        # è¿™é‡Œä¿æŒåŸæœ‰çš„æŸ¥è¯¢é€»è¾‘ä¸å˜
        # ... (ä¸ä¹‹å‰ä¼˜åŒ–çš„APIé€»è¾‘ç›¸åŒ)
        pass
    
    async def get_concepts_daily_ranking(
        self,
        trading_date: str,
        limit: int = 100
    ) -> Dict[str, Any]:
        """è·å–æ¦‚å¿µæ’è¡Œ - æ™ºèƒ½åˆ‡æ¢ç‰ˆæœ¬"""
        
        try:
            if self.use_optimized:
                return await self._get_concepts_ranking_optimized(trading_date, limit)
            else:
                return await self._get_concepts_ranking_legacy(trading_date, limit)
        except Exception as e:
            logger.warning(f"ä¼˜åŒ–æ¦‚å¿µæŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»ŸæŸ¥è¯¢: {e}")
            return await self._get_concepts_ranking_legacy(trading_date, limit)
    
    async def _get_concepts_ranking_optimized(self, trading_date: str, limit: int):
        """ä½¿ç”¨ä¼˜åŒ–è¡¨çš„æ¦‚å¿µæ’è¡ŒæŸ¥è¯¢"""
        
        # ç›´æ¥æŸ¥è¯¢é¢„è®¡ç®—çš„æ’åæ•°æ®
        concepts = self.db.query(ConceptDailyMetrics).filter(
            ConceptDailyMetrics.trading_date == trading_date
        ).order_by(ConceptDailyMetrics.volume_rank).limit(limit).all()
        
        concept_data = []
        for concept in concepts:
            concept_data.append({
                "concept_name": concept.concept_name,
                "total_volume": concept.total_volume,
                "stock_count": concept.stock_count,
                "avg_volume": float(concept.avg_volume),
                "max_volume": concept.max_volume,
                "volume_rank": concept.volume_rank,
                "is_new_high": concept.is_new_high,
                "volume_change_pct": float(concept.volume_change_pct),
                "trading_date": concept.trading_date.strftime('%Y-%m-%d')
            })
        
        return {
            "trading_date": trading_date,
            "concepts": concept_data,
            "performance_info": {
                "query_type": "optimized",
                "returned_count": len(concept_data)
            }
        }
    
    async def get_stock_concepts(
        self,
        stock_code: str,
        trading_date: str
    ) -> Dict[str, Any]:
        """è·å–è‚¡ç¥¨æ¦‚å¿µä¿¡æ¯ - æ™ºèƒ½åˆ‡æ¢ç‰ˆæœ¬"""
        
        try:
            if self.use_optimized:
                return await self._get_stock_concepts_optimized(stock_code, trading_date)
            else:
                return await self._get_stock_concepts_legacy(stock_code, trading_date)
        except Exception as e:
            logger.warning(f"ä¼˜åŒ–è‚¡ç¥¨æ¦‚å¿µæŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»ŸæŸ¥è¯¢: {e}")
            return await self._get_stock_concepts_legacy(stock_code, trading_date)
    
    async def _get_stock_concepts_optimized(self, stock_code: str, trading_date: str):
        """ä½¿ç”¨ä¼˜åŒ–è¡¨çš„è‚¡ç¥¨æ¦‚å¿µæŸ¥è¯¢"""
        
        # ä»å¿«ç…§è¡¨ç›´æ¥æŸ¥è¯¢ï¼Œæ— éœ€JOIN
        concepts = self.db.query(StockConceptDailySnapshot).filter(
            StockConceptDailySnapshot.stock_code == stock_code,
            StockConceptDailySnapshot.trading_date == trading_date
        ).order_by(StockConceptDailySnapshot.concept_total_volume.desc()).all()
        
        concept_list = []
        for concept in concepts:
            concept_list.append({
                "concept_name": concept.concept_name,
                "trading_volume": concept.trading_volume,
                "concept_rank": concept.concept_rank,
                "concept_total_volume": concept.concept_total_volume,
                "volume_percentage": float(concept.volume_percentage),
                "trading_date": concept.trading_date.strftime('%Y-%m-%d')
            })
        
        return {
            "stock_code": stock_code,
            "trading_date": trading_date,
            "concepts": concept_list,
            "performance_info": {
                "query_type": "optimized",
                "returned_count": len(concept_list)
            }
        }
```

### 2.2 ä¿®æ”¹APIæ¥å£ä½¿ç”¨æ–°æœåŠ¡

```python
# backend/app/api/api_v1/endpoints/stock_analysis.py (ä¿®æ”¹éƒ¨åˆ†)

from app.services.optimized_query_service import OptimizedQueryService
import os

# æ·»åŠ ç¯å¢ƒå˜é‡æ§åˆ¶æ˜¯å¦å¯ç”¨ä¼˜åŒ–è¡¨
USE_OPTIMIZED_TABLES = os.getenv('USE_OPTIMIZED_TABLES', 'false').lower() == 'true'

@router.get("/stocks/daily-summary")
async def get_stocks_daily_summary_v2(
    trading_date: Optional[str] = Query(None, description="äº¤æ˜“æ—¥æœŸ YYYY-MM-DD"),
    page: int = Query(1, ge=1, description="é¡µç "),
    size: int = Query(50, ge=1, le=1000, description="æ¯é¡µæ•°é‡"),
    search: Optional[str] = Query(None, description="è‚¡ç¥¨ä»£ç æˆ–åç§°æœç´¢"),
    db: Session = Depends(get_db),
    current_admin: AdminUser = Depends(get_current_admin_user)
):
    """è·å–æŒ‡å®šæ—¥æœŸæ‰€æœ‰è‚¡ç¥¨çš„æ¯æ—¥æ±‡æ€» - æ™ºèƒ½ä¼˜åŒ–ç‰ˆ"""
    try:
        # è§£æäº¤æ˜“æ—¥æœŸ
        if trading_date:
            parsed_date = datetime.strptime(trading_date, '%Y-%m-%d').date()
        else:
            # ä¼˜å…ˆä»æ–°è¡¨è·å–æœ€æ–°æ—¥æœŸ
            if USE_OPTIMIZED_TABLES:
                latest_date = db.query(DailyTradingUnified.trading_date).order_by(
                    DailyTradingUnified.trading_date.desc()
                ).first()
            else:
                latest_date = db.query(DailyTrading.trading_date).order_by(
                    DailyTrading.trading_date.desc()
                ).first()
            parsed_date = latest_date[0] if latest_date else date.today()
        
        # ä½¿ç”¨æ™ºèƒ½æŸ¥è¯¢æœåŠ¡
        query_service = OptimizedQueryService(db, use_optimized=USE_OPTIMIZED_TABLES)
        result = await query_service.get_stocks_daily_summary(
            trading_date=parsed_date.strftime('%Y-%m-%d'),
            page=page,
            size=size,
            search=search
        )
        
        return result
        
    except ValueError:
        raise HTTPException(status_code=400, detail="æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨YYYY-MM-DDæ ¼å¼")
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨æ¯æ—¥æ±‡æ€»å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–è‚¡ç¥¨æ¯æ—¥æ±‡æ€»å¤±è´¥: {str(e)}")

# ç±»ä¼¼åœ°ä¿®æ”¹å…¶ä»–APIæ¥å£...
```

## ğŸ“Š Phase 3: æ•°æ®è¿ç§»å’ŒåŒå†™æ¨¡å¼

### 3.1 ä¿®æ”¹å¯¼å…¥æœåŠ¡æ”¯æŒåŒå†™

```python
# backend/app/services/txt_import.py (ä¿®æ”¹éƒ¨åˆ†)

class TxtImportService:
    def __init__(self):
        self.dual_write = os.getenv('DUAL_WRITE_MODE', 'false').lower() == 'true'
    
    def import_daily_data(self, file_path: str, trading_date: date):
        """å¯¼å…¥æ¯æ—¥æ•°æ® - æ”¯æŒåŒå†™æ¨¡å¼"""
        
        with self.db.begin():
            # 1. è§£ææ•°æ®
            raw_data = self.parse_txt_file(file_path)
            
            # 2. å†™å…¥åŸæœ‰è¡¨ (ä¿æŒä¸å˜)
            self.write_to_legacy_tables(raw_data, trading_date)
            
            # 3. åŒæ—¶å†™å…¥ä¼˜åŒ–è¡¨ (å¦‚æœå¼€å¯åŒå†™)
            if self.dual_write:
                self.write_to_optimized_tables(raw_data, trading_date)
    
    def write_to_optimized_tables(self, raw_data: List[Dict], trading_date: date):
        """å†™å…¥ä¼˜åŒ–è¡¨"""
        
        # 1. æ’å…¥åŸºç¡€äº¤æ˜“æ•°æ®
        trading_records = []
        for record in raw_data:
            stock_name = self.get_stock_name(record['stock_code'])
            trading_records.append({
                'stock_code': record['stock_code'],
                'stock_name': stock_name,
                'trading_date': trading_date,
                'trading_volume': record['trading_volume'],
                'heat_value': record.get('heat_value', 0)
            })
        
        # æ‰¹é‡æ’å…¥
        self.db.bulk_insert_mappings(DailyTradingUnified, trading_records)
        
        # 2. è®¡ç®—å¹¶æ’å…¥æ¦‚å¿µæ±‡æ€»
        self.calculate_and_insert_concept_metrics(trading_date)
        
        # 3. è®¡ç®—å¹¶æ’å…¥è‚¡ç¥¨æ¦‚å¿µå¿«ç…§
        self.calculate_and_insert_stock_concept_snapshot(trading_date)
        
        # 4. æ›´æ–°æ’å
        self.update_rankings(trading_date)
    
    def calculate_and_insert_concept_metrics(self, trading_date: date):
        """è®¡ç®—æ¦‚å¿µæŒ‡æ ‡"""
        # åŸºäºè‚¡ç¥¨æ¦‚å¿µå…³ç³»è®¡ç®—æ±‡æ€»æ•°æ®
        # ...
    
    def update_rankings(self, trading_date: date):
        """æ›´æ–°æ’åä¿¡æ¯"""
        # æ‰¹é‡æ›´æ–°è‚¡ç¥¨æ’å
        # æ‰¹é‡æ›´æ–°æ¦‚å¿µæ’å
        # ...
```

### 3.2 æ‰§è¡Œæ•°æ®è¿ç§»

```bash
# è®¾ç½®åŒå†™æ¨¡å¼
export DUAL_WRITE_MODE=true

# æ‰§è¡Œå†å²æ•°æ®è¿ç§»
python ./scripts/database/migrate_to_optimized_tables.py

# éªŒè¯è¿ç§»ç»“æœ
python -c "
from backend.app.services.optimized_query_service import OptimizedQueryService
from backend.app.core.database import SessionLocal
db = SessionLocal()
service = OptimizedQueryService(db, use_optimized=True)
result = service.get_stocks_daily_summary('2025-09-02', 1, 10)
print('ä¼˜åŒ–æŸ¥è¯¢æµ‹è¯•:', 'OK' if result else 'FAILED')
"
```

## ğŸ”„ Phase 4: åˆ‡æ¢å’ŒéªŒè¯

### 4.1 åˆ‡æ¢åˆ°ä¼˜åŒ–è¡¨

```bash
# 1. åœæ­¢æœåŠ¡
./scripts/deployment/stop.sh

# 2. å¯ç”¨ä¼˜åŒ–è¡¨
export USE_OPTIMIZED_TABLES=true
echo "USE_OPTIMIZED_TABLES=true" >> .env

# 3. é‡å¯æœåŠ¡
./scripts/deployment/start.sh

# 4. éªŒè¯åŠŸèƒ½
curl "http://localhost:3007/api/v1/stock-analysis/stocks/daily-summary?trading_date=2025-09-02&page=1&size=10" \
  -H "Authorization: Bearer YOUR_TOKEN"
```

### 4.2 æ€§èƒ½å¯¹æ¯”éªŒè¯

```python
# scripts/database/performance_comparison.py
import time
import requests

def test_performance():
    base_url = "http://localhost:3007/api/v1/stock-analysis"
    headers = {"Authorization": "Bearer YOUR_TOKEN"}
    
    # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨æŸ¥è¯¢
    start_time = time.time()
    response = requests.get(f"{base_url}/stocks/daily-summary?trading_date=2025-09-02&page=1&size=50", 
                          headers=headers)
    end_time = time.time()
    
    print(f"è‚¡ç¥¨åˆ—è¡¨æŸ¥è¯¢è€—æ—¶: {(end_time - start_time) * 1000:.2f}ms")
    print(f"è¿”å›æ•°æ®: {len(response.json().get('summaries', []))} æ¡")
    print(f"æŸ¥è¯¢ç±»å‹: {response.json().get('performance_info', {}).get('query_type', 'unknown')}")

if __name__ == "__main__":
    test_performance()
```

## ğŸ›ï¸ ç¯å¢ƒå˜é‡é…ç½®

```bash
# .env æ–‡ä»¶æ–°å¢é…ç½®
USE_OPTIMIZED_TABLES=true    # æ˜¯å¦ä½¿ç”¨ä¼˜åŒ–è¡¨
DUAL_WRITE_MODE=false        # æ˜¯å¦åŒå†™æ¨¡å¼
ENABLE_QUERY_CACHE=true      # æ˜¯å¦å¯ç”¨æŸ¥è¯¢ç¼“å­˜
MAX_QUERY_SIZE=1000          # æœ€å¤§æŸ¥è¯¢æ¡æ•°
```

## âš ï¸ å›é€€æ–¹æ¡ˆ

å¦‚æœä¼˜åŒ–è¡¨æœ‰é—®é¢˜ï¼Œå¯ä»¥å¿«é€Ÿå›é€€ï¼š

```bash
# 1. å…³é—­ä¼˜åŒ–è¡¨ä½¿ç”¨
export USE_OPTIMIZED_TABLES=false
echo "USE_OPTIMIZED_TABLES=false" >> .env

# 2. é‡å¯æœåŠ¡
./scripts/deployment/stop.sh
./scripts/deployment/start.sh

# 3. éªŒè¯åŸæœ‰åŠŸèƒ½æ­£å¸¸
curl "http://localhost:3007/api/v1/stock-analysis/stocks/daily-summary?trading_date=2025-09-02"
```

## ğŸ“Š é¢„æœŸç»“æœ

æ‰§è¡Œå®Œæˆåï¼š

1. **APIæ¥å£ä¿æŒä¸å˜** - å‰ç«¯æ— éœ€ä¿®æ”¹
2. **æŸ¥è¯¢æ€§èƒ½å¤§å¹…æå‡** - 5-10ç§’ â†’ 50ms
3. **ç³»ç»Ÿç¨³å®šæ€§æé«˜** - å‡å°‘æ•°æ®åº“è´Ÿè½½
4. **åŠŸèƒ½å®Œå…¨å…¼å®¹** - æ‰€æœ‰ç°æœ‰åŠŸèƒ½æ­£å¸¸

## ğŸ”§ ç»´æŠ¤å‘½ä»¤

```bash
# æ€§èƒ½ç›‘æ§
mysql -e "CALL sp_analyze_query_performance(CURDATE())"

# ç´¢å¼•ç»´æŠ¤  
mysql -e "CALL sp_maintain_indexes()"

# æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
python scripts/database/validate_data_consistency.py
```

---

**å®æ–½æ—¶é—´**: é¢„è®¡4å°æ—¶ | **å½±å“**: æœ€å° | **æ”¶ç›Š**: æŸ¥è¯¢æ€§èƒ½æå‡200å€