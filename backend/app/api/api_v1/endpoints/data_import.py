"""
æ•°æ®å¯¼å…¥ç›¸å…³APIç«¯ç‚¹
"""

from fastapi import APIRouter, Depends, UploadFile, File, HTTPException, Query
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.services.data_import import DataImportService
from app.services.ranking_calculator import RankingCalculatorService
from app.models import DataImportRecord
from datetime import date, datetime
from typing import Optional, List

router = APIRouter()


@router.post("/import-csv")
async def import_csv_data(
    file: UploadFile = File(...),
    allow_overwrite: bool = False,
    db: Session = Depends(get_db)
):
    """å¯¼å…¥CSVæ ¼å¼çš„è‚¡ç¥¨æ•°æ®ï¼ˆé‡æ„ç‰ˆæœ¬ - å¢å¼ºé”™è¯¯å¤„ç†ï¼‰"""
    
    # éªŒè¯æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
    if not file.filename:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º")
    
    if not file.filename.endswith('.csv'):
        raise HTTPException(status_code=400, detail="æ–‡ä»¶å¿…é¡»æ˜¯CSVæ ¼å¼")
    
    # éªŒè¯æ–‡ä»¶å¤§å° (é™åˆ¶100MB)
    if file.size and file.size > 100 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡100MB")
    
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        
        # éªŒè¯æ–‡ä»¶å†…å®¹ä¸ä¸ºç©º
        if not content:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å†…å®¹ä¸ºç©º")
        
        # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆå®é™…è¯»å–åï¼‰
        if len(content) > 100 * 1024 * 1024:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å†…å®¹è¶…è¿‡100MBé™åˆ¶")
        
        print(f"ğŸ“„ å¼€å§‹å¤„ç†CSVæ–‡ä»¶: {file.filename}, å¤§å°: {len(content)} bytes")
        
        # ä½¿ç”¨æ•°æ®å¯¼å…¥æœåŠ¡å¤„ç†æ–‡ä»¶
        import_service = DataImportService(db)
        result = await import_service.import_csv_data(content, file.filename, allow_overwrite)
        
        print(f"âœ… CSVå¤„ç†å®Œæˆ: å¯¼å…¥{result.get('imported_records', 0)}æ¡, è·³è¿‡{result.get('skipped_records', 0)}æ¡")
        
        if result.get("already_exists"):
            return {
                "message": result["message"],
                "filename": file.filename,
                "imported_records": result["imported_records"],
                "skipped_records": result["skipped_records"],
                "import_date": result["import_date"],
                "already_exists": True
            }
        
        return {
            "message": "CSVæ•°æ®å¯¼å…¥æˆåŠŸ" + ("ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰" if result.get("overwrite") else ""),
            "filename": file.filename,
            "imported_records": result["imported_records"],
            "skipped_records": result["skipped_records"],
            "import_date": result["import_date"],
            "overwrite": result.get("overwrite", False),
            "errors": result.get("errors", [])
        }
        
    except HTTPException:
        # é‡æ–°æŠ›å‡ºHTTPå¼‚å¸¸
        raise
    except Exception as e:
        print(f"âŒ CSVå¯¼å…¥å¼‚å¸¸: {str(e)}")
        error_detail = str(e)
        if "CSVè§£æå¤±è´¥" in error_detail:
            raise HTTPException(status_code=400, detail=error_detail)
        else:
            raise HTTPException(status_code=500, detail=f"å¯¼å…¥å¤±è´¥: {error_detail}")


@router.post("/import-txt")
async def import_txt_data(
    file: UploadFile = File(...),
    allow_overwrite: bool = False,
    db: Session = Depends(get_db)
):
    """å¯¼å…¥TXTæ ¼å¼çš„çƒ­åº¦æ•°æ®ï¼ˆé‡æ„ç‰ˆæœ¬ - å¢å¼ºé”™è¯¯å¤„ç†ï¼‰"""
    
    # éªŒè¯æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
    if not file.filename:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º")
    
    if not file.filename.endswith('.txt'):
        raise HTTPException(status_code=400, detail="æ–‡ä»¶å¿…é¡»æ˜¯TXTæ ¼å¼")
    
    # éªŒè¯æ–‡ä»¶å¤§å° (é™åˆ¶50MB)
    if file.size and file.size > 50 * 1024 * 1024:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡50MB")
    
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        
        # éªŒè¯æ–‡ä»¶å†…å®¹ä¸ä¸ºç©º
        if not content:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å†…å®¹ä¸ºç©º")
        
        # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆå®é™…è¯»å–åï¼‰
        if len(content) > 50 * 1024 * 1024:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶å†…å®¹è¶…è¿‡50MBé™åˆ¶")
        
        print(f"ğŸ“„ å¼€å§‹å¤„ç†TXTæ–‡ä»¶: {file.filename}, å¤§å°: {len(content)} bytes")
        
        # ä½¿ç”¨æ•°æ®å¯¼å…¥æœåŠ¡å¤„ç†æ–‡ä»¶
        import_service = DataImportService(db)
        result = await import_service.import_txt_data(content, file.filename, allow_overwrite)
        
        print(f"âœ… TXTå¤„ç†å®Œæˆ: å¯¼å…¥{result.get('imported_records', 0)}æ¡, è·³è¿‡{result.get('skipped_records', 0)}æ¡")
        
        if result.get("already_exists"):
            return {
                "message": result["message"],
                "filename": file.filename,
                "imported_records": result["imported_records"],
                "skipped_records": result["skipped_records"],
                "import_date": result["import_date"],
                "already_exists": True
            }
        
        return {
            "message": "TXTçƒ­åº¦æ•°æ®å¯¼å…¥æˆåŠŸ" + ("ï¼ˆè¦†ç›–æ¨¡å¼ï¼‰" if result.get("overwrite") else ""),
            "filename": file.filename,
            "imported_records": result["imported_records"],
            "skipped_records": result["skipped_records"],
            "import_date": result["import_date"],
            "overwrite": result.get("overwrite", False),
            "errors": result.get("errors", [])
        }
        
    except HTTPException:
        # é‡æ–°æŠ›å‡ºHTTPå¼‚å¸¸
        raise
    except Exception as e:
        print(f"âŒ TXTå¯¼å…¥å¼‚å¸¸: {str(e)}")
        error_detail = str(e)
        if "TXTè§£æå¤±è´¥" in error_detail:
            raise HTTPException(status_code=400, detail=error_detail)
        else:
            raise HTTPException(status_code=500, detail=f"å¯¼å…¥å¤±è´¥: {error_detail}")


@router.post("/calculate-rankings")
def calculate_rankings(
    trade_date: str,
    db: Session = Depends(get_db)
):
    """è®¡ç®—æŒ‡å®šæ—¥æœŸçš„æ’åå’Œæ¦‚å¿µæ€»å’Œ"""
    try:
        # ä½¿ç”¨æ’åè®¡ç®—æœåŠ¡
        calculator = RankingCalculatorService(db)
        result = calculator.calculate_daily_rankings(trade_date)
        
        return {
            "message": "æ’åè®¡ç®—å®Œæˆ",
            "trade_date": trade_date,
            "processed_concepts": result["processed_concepts"],
            "total_rankings": result["total_rankings"],
            "new_highs_found": result["new_highs_found"]
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è®¡ç®—å¤±è´¥: {str(e)}")


@router.get("/import-history")
def get_import_history(
    import_date: Optional[str] = Query(None, description="æŸ¥è¯¢æŒ‡å®šæ—¥æœŸçš„å¯¼å…¥è®°å½• (YYYY-MM-DD)"),
    limit: int = Query(10, description="è¿”å›è®°å½•æ•°é‡é™åˆ¶"),
    db: Session = Depends(get_db)
):
    """è·å–æ•°æ®å¯¼å…¥å†å²è®°å½•"""
    try:
        query = db.query(DataImportRecord)
        
        if import_date:
            try:
                query_date = datetime.strptime(import_date, '%Y-%m-%d').date()
                query = query.filter(DataImportRecord.import_date == query_date)
            except ValueError:
                raise HTTPException(status_code=400, detail="æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º YYYY-MM-DD")
        
        records = query.order_by(DataImportRecord.created_at.desc()).limit(limit).all()
        
        result = []
        for record in records:
            result.append({
                "id": record.id,
                "import_date": record.import_date.isoformat(),
                "import_type": record.import_type,
                "file_name": record.file_name,
                "imported_records": record.imported_records,
                "skipped_records": record.skipped_records,
                "import_status": record.import_status,
                "error_message": record.error_message,
                "created_at": record.created_at.isoformat(),
                "updated_at": record.updated_at.isoformat()
            })
        
        return {
            "records": result,
            "total": len(result)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/import-status/{import_date}")
def check_import_status(
    import_date: str,
    db: Session = Depends(get_db)
):
    """æ£€æŸ¥æŒ‡å®šæ—¥æœŸçš„å¯¼å…¥çŠ¶æ€"""
    try:
        try:
            query_date = datetime.strptime(import_date, '%Y-%m-%d').date()
        except ValueError:
            raise HTTPException(status_code=400, detail="æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œåº”ä¸º YYYY-MM-DD")
        
        records = db.query(DataImportRecord).filter(
            DataImportRecord.import_date == query_date
        ).all()
        
        status = {
            "import_date": import_date,
            "csv_imported": False,
            "txt_imported": False,
            "csv_record": None,
            "txt_record": None
        }
        
        for record in records:
            record_data = {
                "id": record.id,
                "file_name": record.file_name,
                "imported_records": record.imported_records,
                "skipped_records": record.skipped_records,
                "import_status": record.import_status,
                "error_message": record.error_message,
                "created_at": record.created_at.isoformat(),
                "updated_at": record.updated_at.isoformat()
            }
            
            if record.import_type == 'csv':
                status["csv_imported"] = True
                status["csv_record"] = record_data
            elif record.import_type == 'txt':
                status["txt_imported"] = True
                status["txt_record"] = record_data
        
        return status
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")